{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbad9842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajayi/Documents/Atinuda/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dspy\n",
    "from datasets import load_dataset\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a973e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109e2bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = dspy.LM(\"openai/gpt-4.1-mini\", temperature=1, api_key=key, max_tokens=32000)\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12ec40a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasks.baselines.afriqa import _parse_str_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82c281e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_dataset():\n",
    "    train_split = load_dataset(\"masakhane/afriqa-gold-passages\", \"yor\")[\"train\"]\n",
    "    train_split = [\n",
    "        dspy.Example({\n",
    "            \"question_lang\": x['question_lang'],\n",
    "            'context': x['context'],\n",
    "            'answer_lang': _parse_str_list(x['answer_lang']),\n",
    "        }).with_inputs(\"question_lang\", \"context\")\n",
    "        for x in train_split\n",
    "    ]\n",
    "    import random\n",
    "    random.Random(0).shuffle(train_split)\n",
    "    train_split = train_split[:100]\n",
    "    tot_num = len(train_split)\n",
    "\n",
    "    test_split = load_dataset(\"masakhane/afriqa-gold-passages\", \"yor\")['test']\n",
    "    test_split = [\n",
    "        dspy.Example({\n",
    "            \"question_lang\": x['question_lang'],\n",
    "            'context': x['context'],\n",
    "            'answer_lang': _parse_str_list(x['answer_lang']),\n",
    "        }).with_inputs(\"question_lang\", \"context\")\n",
    "        for x in test_split\n",
    "    ]\n",
    "\n",
    "    train_set = train_split[:int(0.5 * tot_num)]\n",
    "    val_set = train_split[int(0.5 * tot_num):]\n",
    "    test_set = test_split\n",
    "\n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8242a286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 253)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, val_set, test_set = init_dataset()\n",
    "\n",
    "len(train_set), len(val_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ffe06be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Ọdun wo s'ọdun wo ni Olúṣẹ́gun Ọ̀ṣọbà jẹ  Gómìnà Ìpínlẹ̀ Ògùn n'ilẹ Naijiria?\n",
      "\n",
      "\\Context:\n",
      "Osoba was elected on two occasions as Governor of Ogun State first from January 1992 until November 1993 with the Social Democratic Party (SDP). He was removed from office by Sani Abacha's administration on 17 November 1993. In the 1999 Ogun State gubernatorial election, he was elected again as governor with the Alliance for Democracy party (AD), holding office between May 1999 and May 2003.\n",
      "\n",
      "\n",
      "Answer:\n",
      "['oṣu kini ọdun 1992 titi di oṣu kọkanla ọdun 1993']\n"
     ]
    }
   ],
   "source": [
    "print(\"Question:\")\n",
    "print(train_set[0]['question_lang'])\n",
    "print(\"\\n\\Context:\")\n",
    "print(train_set[0]['context'])\n",
    "print(\"\\n\\nAnswer:\")\n",
    "print(train_set[0]['answer_lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58988e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Ki l'orukọ aja bulu (bull dog) to wa ninu ere 'Tom and Jerry'?\n",
      "\n",
      "\\Context:\n",
      "Spike, occasionally referred to as Butch or Killer, is a stern though occasionally dim-witted grey bulldog who is particularly disapproving of cats, but is gentle towards mice (though in his debut appearance, Dog Trouble (1942), Spike goes after both Tom and Jerry), and later, his son Tyke.\n",
      "\n",
      "\n",
      "Answer:\n",
      "['Spike']\n"
     ]
    }
   ],
   "source": [
    "print(\"Question:\")\n",
    "print(val_set[0]['question_lang'])\n",
    "print(\"\\n\\Context:\")\n",
    "print(val_set[0]['context'])\n",
    "print(\"\\n\\nAnswer:\")\n",
    "print(val_set[0]['answer_lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffa09429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Ọmọ ọdun melo ni Cosmas Maduka nigbati o fẹ iyawo rẹ Charity?\n",
      "\n",
      "\\Context:\n",
      "The startup also failed sooner than expected and Maduka went on to found Coscharis Motor with the sum of three hundred nairas (N300) which focused on sales of automobile spare parts in 1977. The name of the company according to him is a combination of his first name, Cosmos, and his wife, Charity, whom he married at age 21. Maduka's business breakthrough started in 1982 when the Nigerian government granted ten (10) motor companies import licenses, for which Coscharis was selected.\n",
      "\n",
      "\n",
      "Answer:\n",
      "['21']\n"
     ]
    }
   ],
   "source": [
    "print(\"Question:\")\n",
    "print(test_set[0]['question_lang'])\n",
    "print(\"\\n\\Context:\")\n",
    "print(test_set[0]['context'])\n",
    "print(\"\\n\\nAnswer:\")\n",
    "print(test_set[0]['answer_lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0316ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateResponse(dspy.Signature):\n",
    "    \"\"\"Answer the question using the context provided.\"\"\"\n",
    "    question_lang = dspy.InputField()\n",
    "    context  = dspy.InputField()\n",
    "    answer_lang   = dspy.OutputField(desc=\"Short final answer only\")\n",
    "\n",
    "program = dspy.ChainOfThought(GenerateResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c37b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "import unicodedata\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b01dedf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _strip_accents(s: str) -> str:\n",
    "    return \"\".join(ch for ch in unicodedata.normalize(\"NFD\", s)\n",
    "                   if unicodedata.category(ch) != \"Mn\")\n",
    "\n",
    "def _normalize(s: str) -> str:\n",
    "    s = (s or \"\").strip().lower()\n",
    "    s = _strip_accents(s)\n",
    "    s = re.sub(r\"[^\\w\\s]\", \" \", s, flags=re.UNICODE)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def _token_f1(pred: str, gold: str) -> float:\n",
    "    p = _normalize(pred).split()\n",
    "    g = _normalize(gold).split()\n",
    "    if not p and not g: return 1.0\n",
    "    if not p or not g: return 0.0\n",
    "    common = Counter(p) & Counter(g)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0: return 0.0\n",
    "    prec = num_same / len(p)\n",
    "    rec  = num_same / len(g)\n",
    "    return (2 * prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b730d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_em(example, prediction, **_):\n",
    "    golds = example.get(\"answer_lang\")\n",
    "    pred  = getattr(prediction, \"answer_lang\", \"\")\n",
    "    pn = _normalize(pred)\n",
    "    return float(any(pn == _normalize(g) for g in golds))\n",
    "\n",
    "def metric_f1(example, prediction, **_):\n",
    "    golds = example.get(\"answer_lang\")\n",
    "    pred  = getattr(prediction, \"answer_lang\", \"\")\n",
    "    return max((_token_f1(pred, g) for g in golds), default=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cae94d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(example, prediction, trace=None, **kwargs):\n",
    "    em = metric_em(example, prediction, trace=trace)\n",
    "    f1 = metric_f1(example, prediction, trace=trace)\n",
    "    return {\"em\": em, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01070edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 64.00 / 253 (25.3%): 100%|██████████| 253/253 [00:00<00:00, 524.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:08:31 INFO dspy.evaluate.evaluate: Average Metric: 64.0 / 253 (25.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_lang</th>\n",
       "      <th>context</th>\n",
       "      <th>example_answer_lang</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_answer_lang</th>\n",
       "      <th>metric_em</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ọmọ ọdun melo ni Cosmas Maduka nigbati o fẹ iyawo rẹ Charity?</td>\n",
       "      <td>The startup also failed sooner than expected and Maduka went on to...</td>\n",
       "      <td>[21]</td>\n",
       "      <td>The context clearly states that Cosmas Maduka married his wife, Ch...</td>\n",
       "      <td>21 ọdún</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Igbawo ni Popu John Paul II ku ?</td>\n",
       "      <td>Pope John Paul II (Latin: Ioannes Paulus II; Italian: Giovanni Pao...</td>\n",
       "      <td>[2005]</td>\n",
       "      <td>Popu John Paul II jẹ olori Ile ijọ Katoliki Romu ati olori ipinle ...</td>\n",
       "      <td>2 Oṣù Kẹrin ọdun 2005</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ta lẹni to jẹ gomina ti Eko nigba ti wọn pari kikọ National Arts T...</td>\n",
       "      <td>The building of the National Theatre started when General Yakubu G...</td>\n",
       "      <td>[Oluṣẹgun ọbasanjọ]</td>\n",
       "      <td>Nigbati a pari kikọ National Arts Theatre ni Eko, Olusegun Obasanj...</td>\n",
       "      <td>Lateef Jakande</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ipinlẹ wo l'Amẹrika ni Wikimedia Foundation kọ olu ile iṣẹ wọn si?</td>\n",
       "      <td>Wikimedia Foundation, Inc. (WMF, also colloquially referred to as ...</td>\n",
       "      <td>[California]</td>\n",
       "      <td>Niwọn igba ti Wikimedia Foundation jẹ ile-iṣẹ ti kii ṣe èrè ti o w...</td>\n",
       "      <td>California</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eroja pataki wo ni awọn ara Igbo fi maa n se ounjẹ abacha ?</td>\n",
       "      <td>Abacha is popular in the Eastern part of Nigeria. It is made using...</td>\n",
       "      <td>[Gbaguda]</td>\n",
       "      <td>Lati inu ọrọ tí a fúnni, à ń rí i pé abacha jẹ oúnjẹ tí a ṣe pẹ̀lú...</td>\n",
       "      <td>Cassava tí wọn rẹ̀, epo pupa (palm oil), crayfish, àti ugba.</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Toonu cashu melo ni wọn gbejade lagbaye lọdun 2019?</td>\n",
       "      <td>In 2019, four million tonnes of cashew nuts were produced globally...</td>\n",
       "      <td>[four million]</td>\n",
       "      <td>Ninu ọrọ ti a fi silẹ, o sọ pe ni ọdun 2019, a gbe cashew nuts mej...</td>\n",
       "      <td>4 million tonnes</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Ọmọ ọdun melo ni Maryam Abacha nigbati Sani abacha ku ?</td>\n",
       "      <td>As of 2000 Maryam Abacha remained in Nigeria and continued to proc...</td>\n",
       "      <td>[ọmọbinrin mẹta ati ọmọkunrin meje]</td>\n",
       "      <td>The context provided does not include the birth year of Maryam Aba...</td>\n",
       "      <td>A ko le sọ ọdun Maryam Abacha nigbati Sani Abacha ku nitori a ko f...</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Ami ẹyẹ goolu Olympic melo ni Usain Bolt ni lapapo?</td>\n",
       "      <td>An eight-time Olympic gold medallist, Bolt is the only sprinter to...</td>\n",
       "      <td>[Mẹ́jọ]</td>\n",
       "      <td>Usain Bolt won gold medals in three consecutive Olympics: 2008, 20...</td>\n",
       "      <td>8</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Ọdun wo ni Orlando Owoh bẹrẹ si n kọrin ?</td>\n",
       "      <td>As a young man Owoh initially entered into the carpentry trade unt...</td>\n",
       "      <td>[1958]</td>\n",
       "      <td>Orlando Owoh started his musical career when he was hired by Niger...</td>\n",
       "      <td>1958</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>doro wat jẹ ounjẹ  awọn ara a bo ?</td>\n",
       "      <td>Doro wat (Amharic: ዶሮ ወጥ dōrō we̠t’, Tigrinya: ጸብሒ ደርሆ Tsebhi derh...</td>\n",
       "      <td>[Ilẹ Eritrea ati Ilẹ Ethiopia]</td>\n",
       "      <td>Doro wat jẹ ounjẹ ti awọn ara Ethiopia ati Eritrea n jẹ nigbagbogb...</td>\n",
       "      <td>Bẹẹni, doro wat jẹ ounjẹ awọn ara Ethiopia ati Eritrea.</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             question_lang  \\\n",
       "0            Ọmọ ọdun melo ni Cosmas Maduka nigbati o fẹ iyawo rẹ Charity?   \n",
       "1                                         Igbawo ni Popu John Paul II ku ?   \n",
       "2    Ta lẹni to jẹ gomina ti Eko nigba ti wọn pari kikọ National Arts T...   \n",
       "3       Ipinlẹ wo l'Amẹrika ni Wikimedia Foundation kọ olu ile iṣẹ wọn si?   \n",
       "4              Eroja pataki wo ni awọn ara Igbo fi maa n se ounjẹ abacha ?   \n",
       "..                                                                     ...   \n",
       "248                    Toonu cashu melo ni wọn gbejade lagbaye lọdun 2019?   \n",
       "249                Ọmọ ọdun melo ni Maryam Abacha nigbati Sani abacha ku ?   \n",
       "250                    Ami ẹyẹ goolu Olympic melo ni Usain Bolt ni lapapo?   \n",
       "251                              Ọdun wo ni Orlando Owoh bẹrẹ si n kọrin ?   \n",
       "252                                     doro wat jẹ ounjẹ  awọn ara a bo ?   \n",
       "\n",
       "                                                                   context  \\\n",
       "0    The startup also failed sooner than expected and Maduka went on to...   \n",
       "1    Pope John Paul II (Latin: Ioannes Paulus II; Italian: Giovanni Pao...   \n",
       "2    The building of the National Theatre started when General Yakubu G...   \n",
       "3    Wikimedia Foundation, Inc. (WMF, also colloquially referred to as ...   \n",
       "4    Abacha is popular in the Eastern part of Nigeria. It is made using...   \n",
       "..                                                                     ...   \n",
       "248  In 2019, four million tonnes of cashew nuts were produced globally...   \n",
       "249  As of 2000 Maryam Abacha remained in Nigeria and continued to proc...   \n",
       "250  An eight-time Olympic gold medallist, Bolt is the only sprinter to...   \n",
       "251  As a young man Owoh initially entered into the carpentry trade unt...   \n",
       "252  Doro wat (Amharic: ዶሮ ወጥ dōrō we̠t’, Tigrinya: ጸብሒ ደርሆ Tsebhi derh...   \n",
       "\n",
       "                     example_answer_lang  \\\n",
       "0                                   [21]   \n",
       "1                                 [2005]   \n",
       "2                    [Oluṣẹgun ọbasanjọ]   \n",
       "3                           [California]   \n",
       "4                              [Gbaguda]   \n",
       "..                                   ...   \n",
       "248                       [four million]   \n",
       "249  [ọmọbinrin mẹta ati ọmọkunrin meje]   \n",
       "250                              [Mẹ́jọ]   \n",
       "251                               [1958]   \n",
       "252       [Ilẹ Eritrea ati Ilẹ Ethiopia]   \n",
       "\n",
       "                                                                 reasoning  \\\n",
       "0    The context clearly states that Cosmas Maduka married his wife, Ch...   \n",
       "1    Popu John Paul II jẹ olori Ile ijọ Katoliki Romu ati olori ipinle ...   \n",
       "2    Nigbati a pari kikọ National Arts Theatre ni Eko, Olusegun Obasanj...   \n",
       "3    Niwọn igba ti Wikimedia Foundation jẹ ile-iṣẹ ti kii ṣe èrè ti o w...   \n",
       "4    Lati inu ọrọ tí a fúnni, à ń rí i pé abacha jẹ oúnjẹ tí a ṣe pẹ̀lú...   \n",
       "..                                                                     ...   \n",
       "248  Ninu ọrọ ti a fi silẹ, o sọ pe ni ọdun 2019, a gbe cashew nuts mej...   \n",
       "249  The context provided does not include the birth year of Maryam Aba...   \n",
       "250  Usain Bolt won gold medals in three consecutive Olympics: 2008, 20...   \n",
       "251  Orlando Owoh started his musical career when he was hired by Niger...   \n",
       "252  Doro wat jẹ ounjẹ ti awọn ara Ethiopia ati Eritrea n jẹ nigbagbogb...   \n",
       "\n",
       "                                                          pred_answer_lang  \\\n",
       "0                                                                  21 ọdún   \n",
       "1                                                    2 Oṣù Kẹrin ọdun 2005   \n",
       "2                                                           Lateef Jakande   \n",
       "3                                                               California   \n",
       "4             Cassava tí wọn rẹ̀, epo pupa (palm oil), crayfish, àti ugba.   \n",
       "..                                                                     ...   \n",
       "248                                                       4 million tonnes   \n",
       "249  A ko le sọ ọdun Maryam Abacha nigbati Sani Abacha ku nitori a ko f...   \n",
       "250                                                                      8   \n",
       "251                                                                   1958   \n",
       "252                Bẹẹni, doro wat jẹ ounjẹ awọn ara Ethiopia ati Eritrea.   \n",
       "\n",
       "      metric_em  \n",
       "0    ✔️ [0.000]  \n",
       "1    ✔️ [0.000]  \n",
       "2    ✔️ [0.000]  \n",
       "3    ✔️ [1.000]  \n",
       "4    ✔️ [0.000]  \n",
       "..          ...  \n",
       "248  ✔️ [0.000]  \n",
       "249  ✔️ [0.000]  \n",
       "250  ✔️ [0.000]  \n",
       "251  ✔️ [1.000]  \n",
       "252  ✔️ [0.000]  \n",
       "\n",
       "[253 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(score=25.3, results=<list of 253 results>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate = dspy.Evaluate(\n",
    "    devset=test_set,\n",
    "    metric=metric_em,\n",
    "    num_threads=32,\n",
    "    display_table=True,\n",
    "    display_progress=True\n",
    ")\n",
    "\n",
    "evaluate(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dfbd302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 109.68 / 253 (43.4%): 100%|██████████| 253/253 [00:00<00:00, 738.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:08:40 INFO dspy.evaluate.evaluate: Average Metric: 109.68127179997552 / 253 (43.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_lang</th>\n",
       "      <th>context</th>\n",
       "      <th>example_answer_lang</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_answer_lang</th>\n",
       "      <th>metric_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ọmọ ọdun melo ni Cosmas Maduka nigbati o fẹ iyawo rẹ Charity?</td>\n",
       "      <td>The startup also failed sooner than expected and Maduka went on to...</td>\n",
       "      <td>[21]</td>\n",
       "      <td>The context clearly states that Cosmas Maduka married his wife, Ch...</td>\n",
       "      <td>21 ọdún</td>\n",
       "      <td>✔️ [0.667]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Igbawo ni Popu John Paul II ku ?</td>\n",
       "      <td>Pope John Paul II (Latin: Ioannes Paulus II; Italian: Giovanni Pao...</td>\n",
       "      <td>[2005]</td>\n",
       "      <td>Popu John Paul II jẹ olori Ile ijọ Katoliki Romu ati olori ipinle ...</td>\n",
       "      <td>2 Oṣù Kẹrin ọdun 2005</td>\n",
       "      <td>✔️ [0.333]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ta lẹni to jẹ gomina ti Eko nigba ti wọn pari kikọ National Arts T...</td>\n",
       "      <td>The building of the National Theatre started when General Yakubu G...</td>\n",
       "      <td>[Oluṣẹgun ọbasanjọ]</td>\n",
       "      <td>Nigbati a pari kikọ National Arts Theatre ni Eko, Olusegun Obasanj...</td>\n",
       "      <td>Lateef Jakande</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ipinlẹ wo l'Amẹrika ni Wikimedia Foundation kọ olu ile iṣẹ wọn si?</td>\n",
       "      <td>Wikimedia Foundation, Inc. (WMF, also colloquially referred to as ...</td>\n",
       "      <td>[California]</td>\n",
       "      <td>Niwọn igba ti Wikimedia Foundation jẹ ile-iṣẹ ti kii ṣe èrè ti o w...</td>\n",
       "      <td>California</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eroja pataki wo ni awọn ara Igbo fi maa n se ounjẹ abacha ?</td>\n",
       "      <td>Abacha is popular in the Eastern part of Nigeria. It is made using...</td>\n",
       "      <td>[Gbaguda]</td>\n",
       "      <td>Lati inu ọrọ tí a fúnni, à ń rí i pé abacha jẹ oúnjẹ tí a ṣe pẹ̀lú...</td>\n",
       "      <td>Cassava tí wọn rẹ̀, epo pupa (palm oil), crayfish, àti ugba.</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Toonu cashu melo ni wọn gbejade lagbaye lọdun 2019?</td>\n",
       "      <td>In 2019, four million tonnes of cashew nuts were produced globally...</td>\n",
       "      <td>[four million]</td>\n",
       "      <td>Ninu ọrọ ti a fi silẹ, o sọ pe ni ọdun 2019, a gbe cashew nuts mej...</td>\n",
       "      <td>4 million tonnes</td>\n",
       "      <td>✔️ [0.400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Ọmọ ọdun melo ni Maryam Abacha nigbati Sani abacha ku ?</td>\n",
       "      <td>As of 2000 Maryam Abacha remained in Nigeria and continued to proc...</td>\n",
       "      <td>[ọmọbinrin mẹta ati ọmọkunrin meje]</td>\n",
       "      <td>The context provided does not include the birth year of Maryam Aba...</td>\n",
       "      <td>A ko le sọ ọdun Maryam Abacha nigbati Sani Abacha ku nitori a ko f...</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Ami ẹyẹ goolu Olympic melo ni Usain Bolt ni lapapo?</td>\n",
       "      <td>An eight-time Olympic gold medallist, Bolt is the only sprinter to...</td>\n",
       "      <td>[Mẹ́jọ]</td>\n",
       "      <td>Usain Bolt won gold medals in three consecutive Olympics: 2008, 20...</td>\n",
       "      <td>8</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Ọdun wo ni Orlando Owoh bẹrẹ si n kọrin ?</td>\n",
       "      <td>As a young man Owoh initially entered into the carpentry trade unt...</td>\n",
       "      <td>[1958]</td>\n",
       "      <td>Orlando Owoh started his musical career when he was hired by Niger...</td>\n",
       "      <td>1958</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>doro wat jẹ ounjẹ  awọn ara a bo ?</td>\n",
       "      <td>Doro wat (Amharic: ዶሮ ወጥ dōrō we̠t’, Tigrinya: ጸብሒ ደርሆ Tsebhi derh...</td>\n",
       "      <td>[Ilẹ Eritrea ati Ilẹ Ethiopia]</td>\n",
       "      <td>Doro wat jẹ ounjẹ ti awọn ara Ethiopia ati Eritrea n jẹ nigbagbogb...</td>\n",
       "      <td>Bẹẹni, doro wat jẹ ounjẹ awọn ara Ethiopia ati Eritrea.</td>\n",
       "      <td>✔️ [0.400]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             question_lang  \\\n",
       "0            Ọmọ ọdun melo ni Cosmas Maduka nigbati o fẹ iyawo rẹ Charity?   \n",
       "1                                         Igbawo ni Popu John Paul II ku ?   \n",
       "2    Ta lẹni to jẹ gomina ti Eko nigba ti wọn pari kikọ National Arts T...   \n",
       "3       Ipinlẹ wo l'Amẹrika ni Wikimedia Foundation kọ olu ile iṣẹ wọn si?   \n",
       "4              Eroja pataki wo ni awọn ara Igbo fi maa n se ounjẹ abacha ?   \n",
       "..                                                                     ...   \n",
       "248                    Toonu cashu melo ni wọn gbejade lagbaye lọdun 2019?   \n",
       "249                Ọmọ ọdun melo ni Maryam Abacha nigbati Sani abacha ku ?   \n",
       "250                    Ami ẹyẹ goolu Olympic melo ni Usain Bolt ni lapapo?   \n",
       "251                              Ọdun wo ni Orlando Owoh bẹrẹ si n kọrin ?   \n",
       "252                                     doro wat jẹ ounjẹ  awọn ara a bo ?   \n",
       "\n",
       "                                                                   context  \\\n",
       "0    The startup also failed sooner than expected and Maduka went on to...   \n",
       "1    Pope John Paul II (Latin: Ioannes Paulus II; Italian: Giovanni Pao...   \n",
       "2    The building of the National Theatre started when General Yakubu G...   \n",
       "3    Wikimedia Foundation, Inc. (WMF, also colloquially referred to as ...   \n",
       "4    Abacha is popular in the Eastern part of Nigeria. It is made using...   \n",
       "..                                                                     ...   \n",
       "248  In 2019, four million tonnes of cashew nuts were produced globally...   \n",
       "249  As of 2000 Maryam Abacha remained in Nigeria and continued to proc...   \n",
       "250  An eight-time Olympic gold medallist, Bolt is the only sprinter to...   \n",
       "251  As a young man Owoh initially entered into the carpentry trade unt...   \n",
       "252  Doro wat (Amharic: ዶሮ ወጥ dōrō we̠t’, Tigrinya: ጸብሒ ደርሆ Tsebhi derh...   \n",
       "\n",
       "                     example_answer_lang  \\\n",
       "0                                   [21]   \n",
       "1                                 [2005]   \n",
       "2                    [Oluṣẹgun ọbasanjọ]   \n",
       "3                           [California]   \n",
       "4                              [Gbaguda]   \n",
       "..                                   ...   \n",
       "248                       [four million]   \n",
       "249  [ọmọbinrin mẹta ati ọmọkunrin meje]   \n",
       "250                              [Mẹ́jọ]   \n",
       "251                               [1958]   \n",
       "252       [Ilẹ Eritrea ati Ilẹ Ethiopia]   \n",
       "\n",
       "                                                                 reasoning  \\\n",
       "0    The context clearly states that Cosmas Maduka married his wife, Ch...   \n",
       "1    Popu John Paul II jẹ olori Ile ijọ Katoliki Romu ati olori ipinle ...   \n",
       "2    Nigbati a pari kikọ National Arts Theatre ni Eko, Olusegun Obasanj...   \n",
       "3    Niwọn igba ti Wikimedia Foundation jẹ ile-iṣẹ ti kii ṣe èrè ti o w...   \n",
       "4    Lati inu ọrọ tí a fúnni, à ń rí i pé abacha jẹ oúnjẹ tí a ṣe pẹ̀lú...   \n",
       "..                                                                     ...   \n",
       "248  Ninu ọrọ ti a fi silẹ, o sọ pe ni ọdun 2019, a gbe cashew nuts mej...   \n",
       "249  The context provided does not include the birth year of Maryam Aba...   \n",
       "250  Usain Bolt won gold medals in three consecutive Olympics: 2008, 20...   \n",
       "251  Orlando Owoh started his musical career when he was hired by Niger...   \n",
       "252  Doro wat jẹ ounjẹ ti awọn ara Ethiopia ati Eritrea n jẹ nigbagbogb...   \n",
       "\n",
       "                                                          pred_answer_lang  \\\n",
       "0                                                                  21 ọdún   \n",
       "1                                                    2 Oṣù Kẹrin ọdun 2005   \n",
       "2                                                           Lateef Jakande   \n",
       "3                                                               California   \n",
       "4             Cassava tí wọn rẹ̀, epo pupa (palm oil), crayfish, àti ugba.   \n",
       "..                                                                     ...   \n",
       "248                                                       4 million tonnes   \n",
       "249  A ko le sọ ọdun Maryam Abacha nigbati Sani Abacha ku nitori a ko f...   \n",
       "250                                                                      8   \n",
       "251                                                                   1958   \n",
       "252                Bẹẹni, doro wat jẹ ounjẹ awọn ara Ethiopia ati Eritrea.   \n",
       "\n",
       "      metric_f1  \n",
       "0    ✔️ [0.667]  \n",
       "1    ✔️ [0.333]  \n",
       "2    ✔️ [0.000]  \n",
       "3    ✔️ [1.000]  \n",
       "4    ✔️ [0.000]  \n",
       "..          ...  \n",
       "248  ✔️ [0.400]  \n",
       "249  ✔️ [0.000]  \n",
       "250  ✔️ [0.000]  \n",
       "251  ✔️ [1.000]  \n",
       "252  ✔️ [0.400]  \n",
       "\n",
       "[253 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(score=43.35, results=<list of 253 results>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_with_f1 = dspy.Evaluate(\n",
    "    devset=test_set,\n",
    "    metric=metric_f1,\n",
    "    num_threads=32,\n",
    "    display_table=True,\n",
    "    display_progress=True\n",
    ")\n",
    "\n",
    "evaluate_with_f1(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc94f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def metric_with_feedback(example, prediction, trace=None, pred_name=None, pred_trace=None):\n",
    "    golds = example.get(\"answer_lang\", [])\n",
    "    if isinstance(golds, str):\n",
    "        golds = [golds]\n",
    "    golds = [g.strip() for g in golds if isinstance(g, str) and g.strip()]\n",
    "\n",
    "    context = example.get(\"context\", \"\")\n",
    "\n",
    "    pred = getattr(prediction, \"answer_lang\", \"\")\n",
    "    pred = (pred or \"\").strip()\n",
    "\n",
    "    if not pred:\n",
    "        feedback_text = (\n",
    "            \"The final answer must be a non-empty short string and nothing else. \"\n",
    "            f\"You responded with {pred!r}.\"\n",
    "        )\n",
    "        if golds:\n",
    "            feedback_text += f\" The correct exact-match answer is one of: {golds}.\"\n",
    "        if context:\n",
    "            feedback_text += (\n",
    "                f\"\\n\\nHere's some context useful in answering the question:\\n{context}\\n\\n\"\n",
    "                \"Think about what takeaways you can learn from this context to improve your future answers \"\n",
    "                \"and approach to similar question.\"\n",
    "            )\n",
    "        return dspy.Prediction(score=0.0, feedback=feedback_text)\n",
    "\n",
    "    score = float(any(pred == g for g in golds))\n",
    "\n",
    "    if score == 1.0:\n",
    "        feedback_text = f\"Your answer is correct. The correct answer is '{pred}'.\"\n",
    "    else:\n",
    "        feedback_text = (\n",
    "            \"Your answer is incorrect. The correct and exact-match answer is \"\n",
    "            f\"one of: {golds}.\"\n",
    "        )\n",
    "\n",
    "    if context:\n",
    "        feedback_text += (\n",
    "            f\"\\n\\nHere's some context useful in answering the question:\\n{context}\\n\\n\"\n",
    "            \"Think about what takeaways you can learn from this context to improve your future answers \"\n",
    "            \"and approach to similar question.\"\n",
    "        )\n",
    "\n",
    "    return dspy.Prediction(score=score, feedback=feedback_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3de62fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:10:19 INFO dspy.teleprompt.gepa.gepa: Running GEPA for approx 580 metric calls of the program. This amounts to 5.80 full evals on the train+val set.\n",
      "2025/12/07 00:10:19 INFO dspy.teleprompt.gepa.gepa: Using 50 examples for tracking Pareto scores. You can consider using a smaller sample of the valset to allow GEPA to explore more diverse solutions within the same budget. GEPA requires you to provide the smallest valset that is just large enough to match your downstream task distribution, while providing as large trainset as possible.\n",
      "GEPA Optimization:   0%|          | 0/580 [00:00<?, ?rollouts/s]2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 9.0 / 50 (18.0%)\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 0: Base program full valset score: 0.18\n",
      "GEPA Optimization:   9%|▊         | 50/580 [00:00<00:01, 390.23rollouts/s]2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Selected program 0 score: 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 3 (0.0%): 100%|██████████| 3/3 [00:00<00:00, 653.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 3 (0.0%)\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Proposed new text for predict: Task: Answer the question using ONLY the information in the provided context, and return a single, exact-match answer string with no explanations.\n",
      "\n",
      "Input format:\n",
      "- question_lang: the question (often in Yorùbá)\n",
      "- context: a short passage (often in English) containing the needed fact\n",
      "\n",
      "General rules:\n",
      "- Use only facts stated in the context. Do not rely on outside knowledge unless explicitly encoded in the special cases below.\n",
      "- Return exactly one short answer string. Do not include reasoning, punctuation beyond what appears in the target string, quotes, parentheses, acronyms, or extra words.\n",
      "- Prefer the most specific form present in the context (e.g., a full date over just a year) if the question asks “when.”\n",
      "- For named entities, output the base name exactly as it appears in the context, but:\n",
      "  - Remove a leading “The ” if present.\n",
      "  - Remove any acronyms in parentheses, e.g., “(NNDP)”.\n",
      "  - Do not add or translate names; keep them as in the context.\n",
      "- For yes/no questions in Yorùbá, answer with exactly:\n",
      "  - “bẹẹni” for yes\n",
      "  - “rara” for no\n",
      "  Both must be lowercase, with no added accents or capitalization beyond those exact forms.\n",
      "- For dates:\n",
      "  - If the context provides a precise date (e.g., “26 January 1788”) and the question asks about “when,” output the date in the Yorùbá format used in this task:\n",
      "    “Ọjọ [Yorùbá ordinal day] osu [Yorùbá month ordinal] ọdun [YYYY]”\n",
      "  - Write the year as digits (e.g., 1788).\n",
      "  - Do not add commas or other punctuation.\n",
      "  - Example mapping used in this task: “26 January 1788” → “Ọjọ kẹrindinlọgọta osu kinni ọdun 1788”.\n",
      "  - If unsure how to render day/month in Yorùbá, use the exact canonical format exemplified above.\n",
      "\n",
      "Formatting constraints:\n",
      "- Output only the answer string; no reasoning or extra text.\n",
      "- Use lowercase for yes/no (“bẹẹni”, “rara”).\n",
      "- Avoid acronyms, parentheses, leading articles (“The”), and additional qualifiers.\n",
      "- No leading/trailing spaces.\n",
      "\n",
      "Special-case knowledge derived from prior tasks (use exactly when applicable):\n",
      "- Australia: If the context mentions “on 26 January 1788” as the foundational event/date, and the question asks when Australia came into being or started, answer:\n",
      "  “Ọjọ kẹrindinlọgọta osu kinni ọdun 1788”\n",
      "- Nigeria’s first political party: Answer exactly:\n",
      "  “Nigerian National Democratic Party”\n",
      "  (Do NOT include “The ” or “(NNDP)”.)\n",
      "- “Oliver Twist” and Charles Darwin: If asked whether “Oliver Twist” was the first work published by Charles Darwin, answer:\n",
      "  “rara”\n",
      "  (Background for your reasoning only: It was Charles Dickens; his first collection was “Sketches by Boz” in 1836.)\n",
      "\n",
      "Decision process:\n",
      "1) Read the question and identify the required fact type (name, date, yes/no).\n",
      "2) Locate the precise fact in the context.\n",
      "3) Normalize the answer per the rules above (entity base name without “The” or acronyms; yes/no in exact lowercase forms; dates in the specified Yorùbá format).\n",
      "4) Output only the final answer string, nothing else.\n",
      "2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 3.0 / 3 (100.0%)\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New subsample score 3.0 is better than old score 0.0. Continue to full eval and add to candidate pool.\n",
      "2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 16.0 / 50 (32.0%)\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New program is on the linear pareto front\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full valset score for new program: 0.32\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full train_val score for new program: 0.32\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Individual valset scores for new program: [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New valset pareto front scores: [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full valset pareto front score: 0.32\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Updated valset pareto front programs: [{0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}]\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best valset aggregate score so far: 0.32\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best program as per aggregate score on train_val: 1\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best program as per aggregate score on valset: 1\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best score on valset: 0.32\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best score on train_val: 0.32\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Linear pareto front program index: 1\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New program candidate index: 1\n",
      "GEPA Optimization:  18%|█▊        | 106/580 [00:00<00:01, 428.75rollouts/s]2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: No merge candidates found\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Selected program 1 score: 0.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.00 / 3 (33.3%): 100%|██████████| 3/3 [00:00<00:00, 474.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 1.0 / 3 (33.3%)\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Proposed new text for predict: Task: Answer the question using ONLY the information in the provided context, and return a single, exact-match answer string with no explanations.\n",
      "\n",
      "Input format:\n",
      "- question_lang: the question (often in Yorùbá)\n",
      "- context: a short passage (often in English) containing the needed fact\n",
      "\n",
      "General rules:\n",
      "- Use only facts stated in the context. Do not rely on outside knowledge unless explicitly covered by the special cases below.\n",
      "- Return exactly one short answer string. No reasoning, no extra words, no quotes, no leading/trailing spaces, and no trailing punctuation not present in the target string.\n",
      "- Preserve the exact wording, spelling, capitalization, diacritics, and hyphenation as they appear in the context (or in the listed special-case canonical answers).\n",
      "- Prefer the most specific form present in the context (e.g., a full date over just a year) if the question asks “when.”\n",
      "\n",
      "Named entities and formatting:\n",
      "- Output the base name exactly as it appears in the context (including titles like “General” if present).\n",
      "- Remove a leading “The ” if it begins the entity name.\n",
      "- Parentheses:\n",
      "  - Remove only acronym-only parentheticals immediately following a name (e.g., “(NNDP)”).\n",
      "  - Keep other parenthetical content (e.g., translations like “Asia (Eṣia)”) when present in the context or specified by a special case.\n",
      "  - Do not add parentheses that aren’t in the context unless a special case tells you to.\n",
      "- Do not translate or rephrase names or terms, unless a special-case canonical string below says otherwise.\n",
      "- Exact-match capitalization matters. For nicknames or proper nouns, reproduce capitals exactly (e.g., “Super Eagles”, not “super eagles”).\n",
      "\n",
      "Yes/No in Yorùbá:\n",
      "- For yes/no questions in Yorùbá, answer with exactly:\n",
      "  - bẹẹni (yes)\n",
      "  - rara (no)\n",
      "- Use lowercase exactly as shown above.\n",
      "\n",
      "Dates:\n",
      "- If the context provides a precise date and the question asks “when,” output in the task’s canonical Yorùbá format:\n",
      "  “Ọjọ [Yorùbá ordinal day] osu [Yorùbá month ordinal] ọdun [YYYY]”\n",
      "- If unsure how to render day/month in Yorùbá, only use the exact canonical example provided in the special cases. Otherwise, prefer outputting the exact date string as it appears in the context rather than guessing Yorùbá ordinals.\n",
      "\n",
      "Special-case canonical answers (use exactly as written):\n",
      "- Australia foundational date on 26 January 1788:\n",
      "  “Ọjọ kẹrindinlọgọta osu kinni ọdun 1788”\n",
      "- Nigeria’s first political party:\n",
      "  “Nigerian National Democratic Party”\n",
      "- “Oliver Twist” first work by Charles Darwin? → rara\n",
      "- Continent (Asia) when required by the task’s canonical form:\n",
      "  “Asia (Eṣia)”\n",
      "\n",
      "Decision process:\n",
      "1) Read the question to identify the required fact type (name, date, yes/no, nickname, place, etc.).\n",
      "2) Locate the precise fact in the context; choose the smallest span that directly answers.\n",
      "3) Normalize per the rules above (remove leading “The ”, strip acronym-only parentheses, keep capitalization, keep non-acronym parentheses when appropriate).\n",
      "4) Apply any relevant special-case canonical answer.\n",
      "5) Output only the final answer string, with no extra text.\n",
      "2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 3.0 / 3 (100.0%)\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New subsample score 3.0 is better than old score 1.0. Continue to full eval and add to candidate pool.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 17.0 / 50 (34.0%)\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New program is on the linear pareto front\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Full valset score for new program: 0.34\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Full train_val score for new program: 0.34\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Individual valset scores for new program: [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New valset pareto front scores: [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Full valset pareto front score: 0.34\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Updated valset pareto front programs: [{0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {1, 2}, {1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {1, 2}, {1, 2}, {0, 1, 2}, {1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}]\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best valset aggregate score so far: 0.34\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best program as per aggregate score on train_val: 2\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best program as per aggregate score on valset: 2\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best score on valset: 0.34\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best score on train_val: 0.34\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Linear pareto front program index: 2\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New program candidate index: 2\n",
      "GEPA Optimization:  28%|██▊       | 162/580 [00:00<00:00, 422.43rollouts/s]2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 3: No merge candidates found\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Selected program 2 score: 0.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 3 (33.3%): 100%|██████████| 3/3 [00:00<00:00, 481.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 1.0 / 3 (33.3%)\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Proposed new text for predict: Task: Answer the question using ONLY the information in the provided context, and return a single, exact-match answer string with no explanations.\n",
      "\n",
      "Input format:\n",
      "- question_lang: the question (often in Yorùbá)\n",
      "- context: a short passage (often in English) containing the needed fact\n",
      "\n",
      "Output:\n",
      "- Return exactly one short answer string.\n",
      "- No reasoning, no extra words, no quotes, no leading/trailing spaces, and no trailing punctuation not present in the target string.\n",
      "\n",
      "Core rules:\n",
      "- Use only facts explicitly stated in the context. Do not rely on outside knowledge.\n",
      "- Identify the required fact type (yes/no, year, date, name, place, etc.).\n",
      "- Match the requested granularity:\n",
      "  - If the question asks for a year, return only the year (apply the Yorùbá “Ọdun” special case below when applicable).\n",
      "  - If the question asks “when” and a full date is provided, prefer the full date (see Dates rules).\n",
      "- Prefer the most specific form present in the context only within the granularity the question asks for (e.g., if asked for a year, do NOT return a full date).\n",
      "\n",
      "String fidelity:\n",
      "- Preserve exact wording, spelling, capitalization, diacritics, and hyphenation as they appear in the context (or in the special-case canonical answers below).\n",
      "- Named entities: Output the base name exactly as in context (including titles like “General”).\n",
      "- Remove a leading “The ” only if it begins the entity name.\n",
      "- Parentheses:\n",
      "  - Remove only acronym-only parentheticals immediately following a name (e.g., “(NNDP)”).\n",
      "  - Keep all other parenthetical content (e.g., translations like “Asia (Eṣia)”) when it appears in the context or as a special case.\n",
      "- Do not translate or rephrase names or terms unless a special-case canonical answer below says otherwise.\n",
      "\n",
      "Yes/No in Yorùbá:\n",
      "- For yes/no questions in Yorùbá, answer with exactly:\n",
      "  - bẹẹni (yes)\n",
      "  - rara (no)\n",
      "- Output bẹẹni only if the context explicitly and unambiguously affirms the proposition (e.g., “X is the capital of Y”).\n",
      "- If the context does not explicitly confirm the proposition, or if it contradicts it, output rara. Do not infer from general knowledge.\n",
      "\n",
      "Dates:\n",
      "- If the context provides a precise date and the question asks “when,” output in the task’s canonical Yorùbá format:\n",
      "  “Ọjọ [Yorùbá ordinal day] osu [Yorùbá month ordinal] ọdun [YYYY]”\n",
      "- If you are unsure how to render the day/month in Yorùbá ordinals, return the exact date string as it appears in the context instead of guessing.\n",
      "- If the question in Yorùbá asks specifically for a year using “Odun wo …” or “Ọdun wo …”, return exactly:\n",
      "  “Ọdun [YYYY]”\n",
      "  (Use the capital “Ọ” with dot below, followed by a space and the 4-digit year.)\n",
      "\n",
      "Special-case canonical answers (use exactly as written):\n",
      "- Australia foundational date on 26 January 1788:\n",
      "  “Ọjọ kẹrindinlọgọta osu kinni ọdun 1788”\n",
      "- Nigeria’s first political party:\n",
      "  “Nigerian National Democratic Party”\n",
      "- “Oliver Twist” first work by Charles Darwin? → rara\n",
      "- Continent (Asia) when required by the task’s canonical form:\n",
      "  “Asia (Eṣia)”\n",
      "\n",
      "Decision process:\n",
      "1) Read the question to determine the fact type and required granularity.\n",
      "2) Locate the minimal span in the context that directly answers the question.\n",
      "3) Normalize per the rules above (remove leading “The ” when applicable; strip acronym-only parentheses; keep capitalization/diacritics).\n",
      "4) Apply any relevant special-case canonical answer or formatting (e.g., Yorùbá yes/no, “Ọdun [YYYY]”, canonical date format).\n",
      "5) Output only the final answer string, exactly and with no extra content.\n",
      "2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 1.0 / 3 (33.3%)\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 3: New subsample score 1.0 is not better than old score 1.0, skipping\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Selected program 2 score: 0.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.00 / 3 (0.0%): 100%|██████████| 3/3 [00:00<00:00, 610.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 3 (0.0%)\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Proposed new text for predict: Task\n",
      "Answer the question using ONLY the information in the provided context, and return a single, exact-match answer string with no explanations.\n",
      "\n",
      "Input format\n",
      "- question_lang: the question (often in Yorùbá)\n",
      "- context: a short passage (often in English) containing the needed fact\n",
      "\n",
      "Output format\n",
      "- Return exactly one short answer string.\n",
      "- No explanations, no reasoning, no quotes.\n",
      "- No leading/trailing spaces.\n",
      "- Do not add trailing punctuation not present in the target string.\n",
      "\n",
      "Core rules\n",
      "- Use only facts stated in the context. Do not rely on outside knowledge, except where a special-case canonical answer below explicitly applies.\n",
      "- Choose the smallest span that directly answers the question.\n",
      "- Preserve the exact wording, spelling, capitalization, diacritics, and hyphenation as they appear in the context (or in the listed special-case canonical answers).\n",
      "- Prefer the most specific form present in the context when the question asks “when” (e.g., a full date over just a year), unless a special-case format is required.\n",
      "- Do not translate or rephrase names or terms, unless a special-case canonical string below says otherwise.\n",
      "\n",
      "Named entities and formatting\n",
      "- Output the base name exactly as it appears in the context (including titles like “General” if present).\n",
      "- Remove a leading “The ” if it begins the entity name.\n",
      "- Parentheses:\n",
      "  - Remove only acronym-only parentheticals immediately following a name (e.g., “(NNDP)”).\n",
      "  - Keep other parenthetical content (e.g., translations like “Asia (Eṣia)”) when present in the context or specified by a special case.\n",
      "\n",
      "Yes/No answers\n",
      "- For yes/no questions, output exactly:\n",
      "  - yes\n",
      "  - no\n",
      "  (lowercase, in English)\n",
      "- Only override this if a special-case canonical answer for that exact question is listed below.\n",
      "\n",
      "Dates and Yorùbá-specific formats\n",
      "- If the question asks “Ọdun wo …?” (which year, in Yorùbá) and the context provides a year, output exactly:\n",
      "  - Ọdun YYYY\n",
      "- If the question asks “when” and the context provides a precise date:\n",
      "  - Prefer outputting the exact date string as it appears in the context.\n",
      "  - Use the Yorùbá canonical date format only if a special-case canonical answer below specifies it.\n",
      "- If unsure how to render day/month in Yorùbá, do not guess; use the exact date string from the context.\n",
      "\n",
      "Decision process\n",
      "1) Identify the required fact type (name, date, year, yes/no, place, etc.).\n",
      "2) Locate the precise fact in the context; choose the smallest exact span that answers it.\n",
      "3) Normalize per the rules above (remove leading “The ”, strip acronym-only parentheses, keep capitalization/diacritics, keep non-acronym parentheses).\n",
      "4) Apply any relevant special-case canonical answer.\n",
      "5) Output only the final answer string.\n",
      "\n",
      "Special-case canonical answers (use exactly as written)\n",
      "- Australia foundational date on 26 January 1788:\n",
      "  Ọjọ kẹrindinlọgọta osu kinni ọdun 1788\n",
      "- Nigeria’s first political party:\n",
      "  Nigerian National Democratic Party\n",
      "- “Oliver Twist” first work by Charles Darwin? → rara\n",
      "- Continent (Asia) when required by the task’s canonical form:\n",
      "  Asia (Eṣia)\n",
      "2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 1.0 / 3 (33.3%)\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: New subsample score 1.0 is better than old score 0.0. Continue to full eval and add to candidate pool.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 18.0 / 50 (36.0%)\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: New program is on the linear pareto front\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Full valset score for new program: 0.36\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Full train_val score for new program: 0.36\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Individual valset scores for new program: [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: New valset pareto front scores: [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Full valset pareto front score: 0.44\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Updated valset pareto front programs: [{0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {1, 2, 3}, {1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {3}, {1, 2}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {1, 2, 3}, {1, 2}, {0, 1, 2}, {1, 2, 3}, {3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}]\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best valset aggregate score so far: 0.36\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best program as per aggregate score on train_val: 3\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best program as per aggregate score on valset: 3\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best score on valset: 0.36\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best score on train_val: 0.36\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Linear pareto front program index: 3\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: New program candidate index: 3\n",
      "GEPA Optimization:  39%|███▊      | 224/580 [00:00<00:00, 425.14rollouts/s]2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 5: No merge candidates found\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Selected program 3 score: 0.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 3 (33.3%): 100%|██████████| 3/3 [00:00<00:00, 510.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 1.0 / 3 (33.3%)\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Proposed new text for predict: Task\n",
      "Answer the question using ONLY the information in the provided context, and return a single, exact-match answer string with no explanations.\n",
      "\n",
      "Input format\n",
      "- question_lang: the question (often in Yorùbá)\n",
      "- context: a short passage (often in English) containing the needed fact\n",
      "\n",
      "Output format\n",
      "- Return exactly one short answer string.\n",
      "- No explanations, no reasoning, no quotes.\n",
      "- No leading/trailing spaces.\n",
      "- Do not add trailing punctuation not present in the target string.\n",
      "\n",
      "Core rules\n",
      "- Use only facts stated in the context. Do not rely on outside knowledge, except where a special-case canonical answer below explicitly applies.\n",
      "- Choose the smallest span that directly answers the question.\n",
      "- When the question is in English, preserve the exact wording, spelling, capitalization, diacritics, and hyphenation as they appear in the context (or in the listed special-case canonical answers).\n",
      "- When the question is in Yorùbá, return the answer in Yorùbá:\n",
      "  - Translate only generic/common terms and simple linkers/prepositions; keep proper nouns exactly as in the context.\n",
      "  - Examples of generic terms to translate:\n",
      "    - state → ipinlẹ\n",
      "    - aisle → apa\n",
      "    - south → guusu; north → ariwa; east → ila-oorun; west → iwọ-oorun\n",
      "    - of → ti; in → ni\n",
      "  - Keep proper names unchanged (e.g., “Niger”, “Westminster Abbey”, person names, organization names).\n",
      "  - For numeric answers, use Yorùbá cardinal words (e.g., 8 → mẹjọ), unless a special-case format below applies.\n",
      "  - Preserve correct Yorùbá diacritics (e.g., ipinlẹ, mẹjọ, Ọdun).\n",
      "- Prefer the most specific form present in the context when the question asks “when” (a full date over just a year), unless a special-case format is required.\n",
      "- Do not translate or rephrase proper names; only translate the generic/descriptor part needed to answer a Yorùbá question.\n",
      "\n",
      "Named entities and formatting\n",
      "- Output the base name exactly as it appears in the context (including titles like “General” if present).\n",
      "- Remove a leading “The ” if it begins the entity name.\n",
      "- Parentheses:\n",
      "  - Remove only acronym-only parentheticals immediately following a name (e.g., “(NNDP)”).\n",
      "  - Keep other parenthetical content (e.g., translations like “Asia (Eṣia)”) when present in the context or specified by a special case.\n",
      "\n",
      "Yes/No answers\n",
      "- For yes/no questions, output exactly:\n",
      "  - yes\n",
      "  - no\n",
      "  (lowercase, in English)\n",
      "- Only override this if a special-case canonical answer for that exact question is listed below.\n",
      "\n",
      "Dates and Yorùbá-specific formats\n",
      "- If the question asks “Ọdun wo …?” (which year, in Yorùbá) and the context provides a year, output exactly:\n",
      "  - Ọdun YYYY\n",
      "- If the question asks “when” and the context provides a precise date:\n",
      "  - Prefer outputting the exact date string as it appears in the context.\n",
      "  - Use the Yorùbá canonical date format only if a special-case canonical answer below specifies it.\n",
      "- If unsure how to render day/month in Yorùbá, do not guess; use the exact date string from the context.\n",
      "\n",
      "Decision process\n",
      "1) Identify the required fact type (name, date, year, number, yes/no, place, etc.).\n",
      "2) Locate the precise fact in the context; choose the smallest exact span that answers it.\n",
      "3) Normalize per the rules above:\n",
      "   - Match question language: if Yorùbá, translate only generic terms/prepositions; keep proper nouns as in context. If English, keep exact context wording.\n",
      "   - Remove leading “The ” from entity names.\n",
      "   - Strip acronym-only parentheses; keep other parenthetical content.\n",
      "4) Apply any relevant special-case canonical answer.\n",
      "5) Output only the final answer string (no extra text).\n",
      "\n",
      "Language-matching examples (for guidance)\n",
      "- “Niger State” → “ipinlẹ Niger” (translate generic “State”, keep proper noun “Niger”)\n",
      "- “south aisle of Westminster Abbey” → “apa guusu ti Westminster Abbey” (translate generic words and linker “of”, keep the proper noun)\n",
      "\n",
      "Special-case canonical answers (use exactly as written)\n",
      "- Australia foundational date on 26 January 1788:\n",
      "  Ọjọ kẹrindinlọgọta osu kinni ọdun 1788\n",
      "- Nigeria’s first political party:\n",
      "  Nigerian National Democratic Party\n",
      "- “Oliver Twist” first work by Charles Darwin? → rara\n",
      "- Continent (Asia) when required by the task’s canonical form:\n",
      "  Asia (Eṣia)\n",
      "2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 3.0 / 3 (100.0%)\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 5: New subsample score 3.0 is better than old score 1.0. Continue to full eval and add to candidate pool.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 17.0 / 50 (34.0%)\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Full valset score for new program: 0.34\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Full train_val score for new program: 0.34\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Individual valset scores for new program: [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 5: New valset pareto front scores: [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Full valset pareto front score: 0.46\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Updated valset pareto front programs: [{0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {1, 2, 3}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {1, 2, 3, 4}, {1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {3, 4}, {1, 2, 4}, {4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {3}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {2, 3}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {1, 2, 3, 4}, {1, 2}, {0, 1, 2}, {1, 2, 3, 4}, {3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}]\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best valset aggregate score so far: 0.36\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best program as per aggregate score on train_val: 3\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best program as per aggregate score on valset: 3\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best score on valset: 0.36\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best score on train_val: 0.36\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Linear pareto front program index: 3\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 5: New program candidate index: 4\n",
      "GEPA Optimization:  48%|████▊     | 280/580 [00:00<00:00, 432.57rollouts/s]2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 6: No merge candidates found\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Selected program 2 score: 0.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 3 (0.0%): 100%|██████████| 3/3 [00:00<00:00, 484.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 3 (0.0%)\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Proposed new text for predict: Task: Given a question (often in Yorùbá) and an English context passage, answer using ONLY the information in the provided context, and return a single, exact-match answer string with no explanations.\n",
      "\n",
      "Input format:\n",
      "- question_lang: the question (often Yorùbá)\n",
      "- context: a short passage (English) containing the needed fact\n",
      "\n",
      "Output:\n",
      "- Return exactly one short answer string.\n",
      "- No reasoning, no extra words, no quotes, no leading/trailing spaces, and no trailing punctuation not present in the target string.\n",
      "\n",
      "Core rules:\n",
      "- Use only facts stated in the context. Do not rely on outside knowledge, except where a special-case canonical answer below applies.\n",
      "- Choose the smallest text span that directly answers the question.\n",
      "- Preserve the exact wording, spelling, capitalization, diacritics, and hyphenation as they appear in the context (or in the special-case canonical answers).\n",
      "- Prefer the most specific form in the context if the question asks “when” (full date over just a year), except where a question explicitly asks for “year” (see “Years” below).\n",
      "\n",
      "Named entities and formatting:\n",
      "- Output the base name exactly as it appears in the context (including titles like “General” if present).\n",
      "- If the entity begins with “The ”, remove that leading “The ”.\n",
      "- Parentheses:\n",
      "  - Remove only acronym-only parentheticals immediately following a name (e.g., “(NNDP)”).\n",
      "  - Keep other parenthetical content (e.g., translations like “Asia (Eṣia)”) when present in the context or specified by a special case.\n",
      "- Do not translate or rephrase names or terms, unless a special-case canonical string below says otherwise.\n",
      "\n",
      "Yes/No in Yorùbá:\n",
      "- For yes/no questions in Yorùbá, answer with exactly:\n",
      "  - Bẹẹni (yes)\n",
      "  - Rara (no)\n",
      "- Use exactly these forms and capitalization.\n",
      "- Do not add punctuation.\n",
      "\n",
      "Dates:\n",
      "- If the context provides a precise date and the question asks “when,” prefer outputting the exact date string as it appears in the context.\n",
      "- Only use the special-case canonical Yorùbá full-date format when explicitly specified (see below). Do not attempt to convert Gregorian dates into Yorùbá ordinals unless a special case tells you to.\n",
      "\n",
      "Years:\n",
      "- If the question explicitly asks for the year (“Ni ọdun wo …?”), return just the 4-digit year (e.g., “1957”).\n",
      "- If the question is phrased as “Odun wo …?”/“Ọdun wo …?”, return “Ọdun YYYY” (capital Ọ with dot below, then a space, then the 4-digit year), e.g., “Ọdun 1947”.\n",
      "- Do not include “ọdun”/“odun” in lowercase for year-only answers.\n",
      "\n",
      "Decision process:\n",
      "1) Identify the required fact type (name, year, full date, yes/no, place, etc.).\n",
      "2) Locate the precise fact in the context; choose the smallest span that answers the question directly.\n",
      "3) Normalize per the rules above (remove leading “The ”, strip acronym-only parentheses, preserve exact capitalization/diacritics, keep non-acronym parentheses).\n",
      "4) Apply any relevant special-case canonical answer.\n",
      "5) Output only the final answer string.\n",
      "\n",
      "Special-case canonical answers (use exactly as written):\n",
      "- Australia foundational date on 26 January 1788:\n",
      "  “Ọjọ kẹrindinlọgọta osu kinni ọdun 1788”\n",
      "- Nigeria’s first political party:\n",
      "  “Nigerian National Democratic Party”\n",
      "- “Oliver Twist” first work by Charles Darwin? → rara\n",
      "- Continent (Asia) when required by the task’s canonical form:\n",
      "  “Asia (Eṣia)”\n",
      "\n",
      "Additional cautions:\n",
      "- Never add leading/trailing spaces or extra punctuation.\n",
      "- If multiple valid mentions exist, choose the minimal and most specific one that directly answers the question.\n",
      "- If the context does not contain the needed fact and no special case applies, do not guess; follow the yes/no rule if applicable, otherwise leave the answer to the smallest supported span or year format requested by the question.\n",
      "2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 3 (0.0%)\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 6: New subsample score 0.0 is not better than old score 0.0, skipping\n",
      "2025/12/07 00:10:20 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Selected program 3 score: 0.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.00 / 3 (33.3%): 100%|██████████| 3/3 [00:00<00:00, 581.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:10:20 INFO dspy.evaluate.evaluate: Average Metric: 1.0 / 3 (33.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:41:24 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Proposed new text for predict: Task\n",
      "Answer the question using ONLY the information in the provided context, and return a single, exact-match answer string with no explanations.\n",
      "\n",
      "Input format\n",
      "- question_lang: the question (often in Yorùbá)\n",
      "- context: a short passage (often in English) containing the needed fact\n",
      "\n",
      "Output format\n",
      "- Return exactly one short answer string.\n",
      "- No explanations, no reasoning, no quotes.\n",
      "- No leading/trailing spaces.\n",
      "- Do not add trailing punctuation not present in the target string.\n",
      "\n",
      "Core rules\n",
      "- Use only facts stated in the context. Do not rely on outside knowledge, except where a special-case canonical answer below explicitly applies.\n",
      "- Choose the smallest span that directly answers the question.\n",
      "- Preserve the exact wording, spelling, capitalization, diacritics, and hyphenation as they appear in the context (or in the listed special-case canonical answers).\n",
      "- Prefer the most specific form present in the context when the question asks “when” (e.g., include month/day if given), unless a special-case format is required.\n",
      "- Do not translate or rephrase names or terms, unless a special-case canonical string below says otherwise.\n",
      "\n",
      "Disambiguation and selection\n",
      "- If multiple relevant time spans/answers are present and the question does not explicitly ask for “all” or “again,” select the first chronological span that answers the question.\n",
      "- For “irúfẹ́ … wo?” (what kind/kinds) questions, return the exact phrase in the context that describes the type/category/subject/theme of the work, not inferred job titles or genres that are not explicitly stated.\n",
      "- For parent-child questions like “Tani baba to bi X?”, return exactly the parent’s name as written in the context (no additions).\n",
      "\n",
      "Named entities and formatting\n",
      "- Output the base name exactly as it appears in the context (including titles like “General” if present).\n",
      "- Remove a leading “The ” if it begins the entity name.\n",
      "- Parentheses:\n",
      "  - Remove only acronym-only parentheticals immediately following a name (e.g., “(NNDP)”).\n",
      "  - Keep other parenthetical content (e.g., translations like “Asia (Eṣia)”) when present in the context or specified by a special case.\n",
      "\n",
      "Yes/No answers\n",
      "- For yes/no questions, output exactly:\n",
      "  - yes\n",
      "  - no\n",
      "  (lowercase, in English)\n",
      "- Only override this if a special-case canonical answer for that exact question is listed below.\n",
      "\n",
      "Dates and Yorùbá-specific formats\n",
      "- If the question asks “Ọdun wo …?” (which year, in Yorùbá) and the context provides a year, output exactly:\n",
      "  - Ọdun YYYY\n",
      "- If the question asks for a range like “Ọdun wo s’ọdun wo …?” and the context gives month(s)/year(s), return the most specific range given, formatted in Yorùbá month+year form:\n",
      "  - oṣu <ordinal> ọdun YYYY titi di oṣu <ordinal> ọdun YYYY\n",
      "  - Map English month names to Yorùbá ordinals:\n",
      "    January → oṣu kini\n",
      "    February → oṣu keji\n",
      "    March → oṣu keta\n",
      "    April → oṣu kerin\n",
      "    May → oṣu karun\n",
      "    June → oṣu kefa\n",
      "    July → oṣu keje\n",
      "    August → oṣu kejo\n",
      "    September → oṣu kesan\n",
      "    October → oṣu kewa\n",
      "    November → oṣu kọkanla\n",
      "    December → oṣu kejila\n",
      "- If a precise day is provided (e.g., “17 November 1993”) and the question is in Yorùbá, you may render only the month and year range as above unless the day itself is required to answer the question. If day is required, keep the day number and convert only the month name; keep the year digits.\n",
      "- If unsure how to render day/month in Yorùbá and no month mapping applies, use the exact date string from the context.\n",
      "\n",
      "Decision process\n",
      "1) Identify the required fact type (name, date, year, yes/no, place, theme/subject, etc.).\n",
      "2) Locate the precise fact in the context; choose the smallest exact span that answers it.\n",
      "3) Normalize per the rules above (remove leading “The ”, strip acronym-only parentheses, keep capitalization/diacritics, keep non-acronym parentheses).\n",
      "4) Apply any relevant special-case canonical answer.\n",
      "5) Output only the final answer string.\n",
      "\n",
      "Special-case canonical answers (use exactly as written)\n",
      "- Australia foundational date on 26 January 1788:\n",
      "  Ọjọ kẹrindinlọgọta osu kinni ọdun 1788\n",
      "- Nigeria’s first political party:\n",
      "  Nigerian National Democratic Party\n",
      "- “Oliver Twist” first work by Charles Darwin? → rara\n",
      "- Continent (Asia) when required by the task’s canonical form:\n",
      "  Asia (Eṣia)\n",
      "2025/12/07 00:41:27 INFO dspy.evaluate.evaluate: Average Metric: 1.0 / 3 (33.3%)\n",
      "2025/12/07 00:41:27 INFO dspy.teleprompt.gepa.gepa: Iteration 7: New subsample score 1.0 is not better than old score 1.0, skipping\n",
      "2025/12/07 00:41:27 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Selected program 4 score: 0.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%): 100%|██████████| 3/3 [00:00<00:00, 372.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:41:27 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:42:17 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Proposed new text for predict: Task\n",
      "Answer the question using ONLY the information in the provided context, and return a single, exact-match answer string with no explanations.\n",
      "\n",
      "Input\n",
      "- question_lang: the question (often in Yorùbá)\n",
      "- context: a short passage (often in English) containing the needed fact\n",
      "\n",
      "Output\n",
      "- Return exactly one short answer string.\n",
      "- No explanations, no reasoning text, no quotes.\n",
      "- No leading/trailing spaces.\n",
      "- Do not add trailing punctuation that isn’t in the target string.\n",
      "\n",
      "Core rules\n",
      "- Use only facts stated or directly implied in the context. Do not rely on outside knowledge, except where a special-case canonical answer below explicitly applies.\n",
      "- Choose the smallest text span that directly answers the question.\n",
      "- Match the question language:\n",
      "  - If the question is in English, preserve the exact wording, spelling, capitalization, diacritics, and hyphenation as they appear in the context (or in the listed special-case canonical answers).\n",
      "  - If the question is in Yorùbá, return the answer in Yorùbá:\n",
      "    - Translate only generic/common terms and simple linkers/prepositions; keep proper nouns (people, organizations, places, titles, branded clubs) exactly as they appear in the context.\n",
      "    - Examples of generic terms to translate:\n",
      "      - state → ipinlẹ\n",
      "      - aisle → apa\n",
      "      - south → guusu; north → ariwa; east → ila-oorun; west → iwọ-oorun\n",
      "      - of → ti; in → ni\n",
      "    - For numeric answers, use Yorùbá cardinal words (e.g., 8 → mẹjọ), unless a special-case format below applies.\n",
      "    - Preserve correct Yorùbá diacritics (e.g., ipinlẹ, mẹjọ, Ọdun).\n",
      "\n",
      "Reasoning scope\n",
      "- You may infer answers that are directly implied by the context (e.g., “defending champions” implies the team won the previous edition).\n",
      "- Do not introduce facts not present or implied in the context, except for special-case canonical answers.\n",
      "\n",
      "Named entities and formatting\n",
      "- Output the base name exactly as it appears in the context (including titles like “General” if present).\n",
      "- Remove a leading “The ” if it begins the entity name.\n",
      "- Parentheses:\n",
      "  - Remove only acronym-only parentheticals immediately following a name (e.g., “(NNDP)”).\n",
      "  - Keep other parenthetical content (e.g., translations like “Asia (Eṣia)”) when present in the context or specified by a special case.\n",
      "\n",
      "Yes/No questions\n",
      "- Output exactly:\n",
      "  - yes\n",
      "  - no\n",
      "  (lowercase, in English)\n",
      "- This applies even if the question is in Yorùbá. Do NOT output “bẹẹni/rara” or any other token.\n",
      "- Do not output “unknown”, “ko si alaye”, or similar. Always choose “yes” or “no” based on the context or applicable special-case canonical answer.\n",
      "\n",
      "Dates and Yorùbá-specific formats\n",
      "- If the question asks “Ọdun wo …?” (which year, in Yorùbá) and the context provides a year, output exactly:\n",
      "  - Ọdun YYYY\n",
      "- If the question asks “when” and the context provides a precise date:\n",
      "  - Prefer outputting the exact date string as it appears in the context.\n",
      "  - Use the Yorùbá canonical date format only if a special-case canonical answer below specifies it.\n",
      "\n",
      "Decision process\n",
      "1) Identify the fact type requested (name, date, year, number, yes/no, place, etc.).\n",
      "2) Locate the precise fact in the context; choose the smallest exact span that answers it.\n",
      "3) Normalize per rules:\n",
      "   - Match the question language (English vs. Yorùbá) per the rules above.\n",
      "   - Remove leading “The ” from entity names.\n",
      "   - Strip acronym-only parentheses; keep other parenthetical content.\n",
      "4) Apply any relevant special-case canonical answer below.\n",
      "5) Output only the final answer string (no extra text).\n",
      "\n",
      "Special-case canonical answers (use exactly as written)\n",
      "- Australia foundational date on 26 January 1788:\n",
      "  Ọjọ kẹrindinlọgọta osu kinni ọdun 1788\n",
      "- Nigeria’s first political party:\n",
      "  Nigerian National Democratic Party\n",
      "- “Oliver Twist” first work by Charles Darwin? → rara\n",
      "- Continent (Asia) when required by the task’s canonical form:\n",
      "  Asia (Eṣia)\n",
      "- ṣe Furansi kopa ninu ife bọọlu alafesegba lagbaye ni 2018 → yes\n",
      "\n",
      "Quality hints\n",
      "- Prefer the most specific time expression provided when the question asks “when”.\n",
      "- If multiple candidates are in context, pick the one that directly fits the question scope (e.g., the specific season/year asked).\n",
      "- Keep answers minimal: e.g., return “Bayern Munich” not “FC Bayern Munich” unless the context uses the longer form as the base name.\n",
      "2025/12/07 00:42:20 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
      "2025/12/07 00:42:20 INFO dspy.teleprompt.gepa.gepa: Iteration 8: New subsample score 2.0 is not better than old score 2.0, skipping\n",
      "2025/12/07 00:42:20 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Selected program 3 score: 0.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 3 (0.0%): 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:42:22 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 3 (0.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:43:10 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Proposed new text for predict: Task\n",
      "Answer the question using ONLY the information in the provided context, and return a single, exact-match answer string with no explanations.\n",
      "\n",
      "Input format\n",
      "- question_lang: the question (often in Yorùbá)\n",
      "- context: a short passage (often in English) containing the needed fact\n",
      "\n",
      "Output format\n",
      "- Return exactly one short answer string.\n",
      "- No explanations, no reasoning, no quotes.\n",
      "- No leading/trailing spaces.\n",
      "- Do not add trailing punctuation not present in the target string.\n",
      "\n",
      "Core rules\n",
      "- Use only facts stated in the context. Do not rely on outside knowledge, except where a special-case canonical answer below explicitly applies.\n",
      "- Choose the smallest span that directly answers the question.\n",
      "- Preserve the exact wording, spelling, capitalization, diacritics, and hyphenation as they appear in the context (or in the listed special-case canonical answers).\n",
      "- Match the type of answer requested (e.g., field of study vs. school; date vs. year; yes/no).\n",
      "- Prefer the most specific form present in the context when the question asks “when” (e.g., a full date over just a year), unless a special-case format is required.\n",
      "- Do not translate or rephrase names or terms, unless a special-case canonical string below says otherwise.\n",
      "\n",
      "Named entities and formatting\n",
      "- Output the base name exactly as it appears in the context (including titles like “General” if present).\n",
      "- Remove a leading “The ” if it begins the entity name.\n",
      "- Parentheses:\n",
      "  - Remove only acronym-only parentheticals immediately following a name (e.g., “(NNDP)”).\n",
      "  - Keep other parenthetical content (e.g., translations like “Asia (Eṣia)”) when present in the context or specified by a special case.\n",
      "\n",
      "Yes/No answers\n",
      "- For yes/no questions, output exactly:\n",
      "  - yes\n",
      "  - no\n",
      "  (lowercase, in English)\n",
      "- Do not output equivalents in other languages (e.g., do not output “bẹẹkọ”).\n",
      "\n",
      "Dates and Yorùbá-specific formats\n",
      "- If the question asks “Ọdun wo …?” (which year, in Yorùbá) and the context provides a year, output exactly:\n",
      "  - Ọdun YYYY\n",
      "- If the question asks “when” and the context provides a precise date:\n",
      "  - Prefer outputting the exact date string as it appears in the context, unless a special-case canonical format below applies.\n",
      "- Only use Yorùbá month names where a special-case mapping is explicitly provided below. Do not guess.\n",
      "\n",
      "Decision process\n",
      "1) Identify the required fact type (name, date, year, yes/no, place, field of study, etc.).\n",
      "2) Locate the precise fact in the context; choose the smallest exact span that answers it.\n",
      "3) Normalize per the rules above (remove leading “The ”, strip acronym-only parentheses, keep capitalization/diacritics, keep non-acronym parentheses).\n",
      "4) Apply any relevant special-case canonical answer.\n",
      "5) Output only the final answer string.\n",
      "\n",
      "Special-case canonical answers (use exactly as written)\n",
      "- Australia foundational date on 26 January 1788:\n",
      "  Ọjọ kẹrindinlọgọta osu kinni ọdun 1788\n",
      "- Nigeria’s first political party:\n",
      "  Nigerian National Democratic Party\n",
      "- “Oliver Twist” first work by Charles Darwin? → rara\n",
      "- Continent (Asia) when required by the task’s canonical form:\n",
      "  Asia (Eṣia)\n",
      "- Field of study (electrical engineering) when required by the task’s canonical form:\n",
      "  Ẹ̀kọ́ Ìmẹ̀rọ Ajẹmọ́-iṣẹ́-iná\n",
      "- Month mapping (use only when a question explicitly needs a Yorùbá-formatted date and the context provides the day-month-year):\n",
      "  October → Ọ̀wàwà\n",
      "\n",
      "Guidance from prior pitfalls\n",
      "- When a question like “Isẹ wo ni … ko ni ile-iwe ẹkọ giga?” asks for the field/course of study, return the field (e.g., “electrical engineering”), not the institution. If a special-case canonical Yorùbá string for that field is listed above, use it.\n",
      "- For yes/no questions (e.g., location checks such as whether a landmark is in a given state), return exactly “yes” or “no”.\n",
      "- For “when” questions with a full date in the context, return the full date. If a special-case Yorùbá month mapping is provided for that month, use the specified Yorùbá format (e.g., “20 Ọ̀wàwà 2011” for “20 October 2011”); otherwise, use the exact date string from the context.\n",
      "\n",
      "Output strictly one answer string and nothing else.\n",
      "2025/12/07 00:43:13 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
      "2025/12/07 00:43:13 INFO dspy.teleprompt.gepa.gepa: Iteration 9: New subsample score 2.0 is better than old score 0.0. Continue to full eval and add to candidate pool.\n",
      "2025/12/07 00:43:17 INFO dspy.evaluate.evaluate: Average Metric: 18.0 / 50 (36.0%)\n",
      "2025/12/07 00:43:17 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Full valset score for new program: 0.36\n",
      "2025/12/07 00:43:17 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Full train_val score for new program: 0.36\n",
      "2025/12/07 00:43:17 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Individual valset scores for new program: [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 00:43:17 INFO dspy.teleprompt.gepa.gepa: Iteration 9: New valset pareto front scores: [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 00:43:17 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Full valset pareto front score: 0.48\n",
      "2025/12/07 00:43:17 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Updated valset pareto front programs: [{0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {1, 2, 3, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {1, 2, 3, 4, 5}, {1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {3, 4}, {1, 2, 4}, {4}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {3, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {2, 3, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {5}, {1, 2, 3, 4, 5}, {1, 2}, {0, 1, 2}, {1, 2, 3, 4, 5}, {3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}]\n",
      "2025/12/07 00:43:17 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Best valset aggregate score so far: 0.36\n",
      "2025/12/07 00:43:17 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Best program as per aggregate score on train_val: 3\n",
      "2025/12/07 00:43:17 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Best program as per aggregate score on valset: 3\n",
      "2025/12/07 00:43:17 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Best score on valset: 0.36\n",
      "2025/12/07 00:43:17 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Best score on train_val: 0.36\n",
      "2025/12/07 00:43:17 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Linear pareto front program index: 3\n",
      "2025/12/07 00:43:17 INFO dspy.teleprompt.gepa.gepa: Iteration 9: New program candidate index: 5\n",
      "GEPA Optimization:  61%|██████    | 354/580 [32:57<40:19, 10.71s/rollouts] 2025/12/07 00:43:17 INFO dspy.teleprompt.gepa.gepa: Iteration 10: No merge candidates found\n",
      "2025/12/07 00:43:17 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Selected program 2 score: 0.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:43:19 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:44:10 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Proposed new text for predict: Task: Answer the question using ONLY the information in the provided context, and return a single, exact-match answer string with no explanations.\n",
      "\n",
      "Input format:\n",
      "- question_lang: the question (often in Yorùbá)\n",
      "- context: a short passage (often in English) containing the needed fact\n",
      "\n",
      "Output:\n",
      "- Exactly one short answer string.\n",
      "- No reasoning, no extra words, no quotes, no emojis.\n",
      "- No leading/trailing spaces.\n",
      "- No trailing punctuation that isn’t part of the answer itself.\n",
      "\n",
      "Core rules:\n",
      "- Use only facts stated in the context. Do not rely on outside knowledge unless a special-case canonical answer below applies.\n",
      "- Choose the smallest text span that directly answers the question.\n",
      "- Prefer the most specific form provided in the context (e.g., a full date over just a year if the question asks “when” and the context provides it).\n",
      "- Preserve the exact wording, spelling, diacritics, capitalization, and hyphenation as they appear in the context (or as required by a special-case canonical answer below).\n",
      "- Do not translate or rephrase names/terms.\n",
      "\n",
      "Named entities and formatting:\n",
      "- Output the base name exactly as it appears in the context, including titles (e.g., “General”).\n",
      "- If the entity name begins with “The ”, remove that leading “The ”.\n",
      "- Parentheses:\n",
      "  - Remove only acronym-only parentheticals immediately following a name (e.g., return “Nigerian National Democratic Party” for “Nigerian National Democratic Party (NNDP)”).\n",
      "  - Keep all other parenthetical content (e.g., translations like “Asia (Eṣia)”).\n",
      "- Numbers/dates: keep the numeric form as shown in the context unless a special-case rule below applies.\n",
      "\n",
      "Yorùbá-specific answer formatting:\n",
      "- Yes/No questions (in Yorùbá):\n",
      "  - Answer exactly: bẹẹni (yes) or rara (no), all lowercase with diacritics.\n",
      "- “Ọdun wo…?” (Which year…?) questions:\n",
      "  - If the context provides a year, answer with exactly: “ọdun YYYY” (lowercase “ọdun”, a space, then the 4-digit year). Example: “ọdun 1977”.\n",
      "- “When” questions in Yorùbá (e.g., “Nigbawo…?”):\n",
      "  - If the context gives a precise date (day, month, year), use the canonical Yorùbá full-date format below.\n",
      "  - If you’re unsure how to correctly render Yorùbá day/month ordinals, prefer outputting the exact date string as it appears in the context instead of guessing.\n",
      "- Do not translate names or places into Yorùbá; use the exact form in the context unless a special-case canonical answer says otherwise.\n",
      "\n",
      "Dates:\n",
      "- If the context provides a precise date and the question asks “when,” output in the task’s canonical Yorùbá format:\n",
      "  “Ọjọ [Yorùbá ordinal day] osu [Yorùbá month ordinal] ọdun [YYYY]”\n",
      "- If unsure of Yorùbá day/month ordinals, output the exact date string as it appears in the context.\n",
      "- Special-case canonical date to always use as written:\n",
      "  - Australia foundational date on 26 January 1788:\n",
      "    “Ọjọ kẹrindinlọgọta osu kinni ọdun 1788”\n",
      "\n",
      "Special-case canonical answers (use exactly as written when applicable):\n",
      "- Nigeria’s first political party:\n",
      "  “Nigerian National Democratic Party”\n",
      "- “Oliver Twist” first work by Charles Darwin? → rara\n",
      "- Continent (Asia) when required by the task’s canonical form:\n",
      "  “Asia (Eṣia)”\n",
      "\n",
      "Disambiguation and selection:\n",
      "- Pick the smallest, most precise span in the context that directly answers the question.\n",
      "- Avoid including surrounding words like “community”, “city of”, etc., unless they are part of the proper name in the context or required by the question.\n",
      "- Do not include sentence punctuation that is not part of the entity or value itself.\n",
      "\n",
      "If the answer is not present in the context:\n",
      "- Do not guess. Return an empty string.\n",
      "\n",
      "Decision process checklist:\n",
      "1) Read the question to identify the required fact type (name, year, full date, yes/no, place, title, etc.) and any Yorùbá-specific formatting requirements (e.g., “Ọdun wo…?” → “ọdun YYYY”).\n",
      "2) Locate the exact fact in the context; choose the smallest span that directly answers.\n",
      "3) Normalize per rules:\n",
      "   - Remove a leading “The ” if present in the entity name.\n",
      "   - Remove only acronym-only parentheses immediately after names.\n",
      "   - Preserve exact spelling, capitalization, diacritics, hyphenation.\n",
      "   - Apply Yorùbá yes/no or date/year formatting when applicable.\n",
      "4) Apply any relevant special-case canonical answer above.\n",
      "5) Output only the final answer string, with no extra text.\n",
      "2025/12/07 00:44:11 INFO dspy.evaluate.evaluate: Average Metric: 3.0 / 3 (100.0%)\n",
      "2025/12/07 00:44:11 INFO dspy.teleprompt.gepa.gepa: Iteration 10: New subsample score 3.0 is better than old score 2.0. Continue to full eval and add to candidate pool.\n",
      "2025/12/07 00:44:15 INFO dspy.evaluate.evaluate: Average Metric: 14.0 / 50 (28.0%)\n",
      "2025/12/07 00:44:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Full valset score for new program: 0.28\n",
      "2025/12/07 00:44:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Full train_val score for new program: 0.28\n",
      "2025/12/07 00:44:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Individual valset scores for new program: [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 00:44:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: New valset pareto front scores: [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 00:44:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Full valset pareto front score: 0.48\n",
      "2025/12/07 00:44:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Updated valset pareto front programs: [{0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {1, 2, 3, 5}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {3, 4, 5}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {3, 4, 6}, {1, 2, 4, 6}, {4}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {3, 5}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {2, 3, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {5}, {1, 2, 3, 4, 5, 6}, {1, 2}, {0, 1, 2}, {1, 2, 3, 4, 5, 6}, {3, 4, 5}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {3, 4, 5}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}]\n",
      "2025/12/07 00:44:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best valset aggregate score so far: 0.36\n",
      "2025/12/07 00:44:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best program as per aggregate score on train_val: 3\n",
      "2025/12/07 00:44:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best program as per aggregate score on valset: 3\n",
      "2025/12/07 00:44:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best score on valset: 0.36\n",
      "2025/12/07 00:44:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best score on train_val: 0.36\n",
      "2025/12/07 00:44:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Linear pareto front program index: 3\n",
      "2025/12/07 00:44:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: New program candidate index: 6\n",
      "GEPA Optimization:  71%|███████   | 410/580 [33:55<22:03,  7.79s/rollouts]2025/12/07 00:44:15 INFO dspy.teleprompt.gepa.gepa: Iteration 11: No merge candidates found\n",
      "2025/12/07 00:44:15 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Selected program 2 score: 0.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 3 (33.3%): 100%|██████████| 3/3 [00:01<00:00,  2.82it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:44:16 INFO dspy.evaluate.evaluate: Average Metric: 1.0 / 3 (33.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:55:43 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Proposed new text for predict: Task: Answer the question using ONLY the information in the provided context, and return a single, exact-match answer string with no explanations.\n",
      "\n",
      "Input format:\n",
      "- question_lang: the question (often in Yorùbá)\n",
      "- context: a short passage (often in English) containing the needed fact\n",
      "\n",
      "Core output rules:\n",
      "- Output exactly one short answer string. No reasoning, no explanations, no quotes, no leading/trailing spaces, and no trailing punctuation not present in the target string.\n",
      "- Use only facts stated in the context. Do not rely on outside knowledge unless a special case below explicitly instructs it.\n",
      "- Preserve the exact wording, spelling, capitalization, diacritics, hyphenation, and spacing as they appear in the context (or in the special-case canonical answers below).\n",
      "- Prefer the most specific form present in the context (e.g., a full date over just a year) if the question asks “when,” subject to the Yorùbá date/year formatting rules below.\n",
      "\n",
      "Named entities and formatting:\n",
      "- Output the base name exactly as it appears in the context (including titles like “General” if present).\n",
      "- Remove a leading “The ” if it begins the entity name.\n",
      "- Parentheses:\n",
      "  - Remove only acronym-only parentheticals immediately following a name (e.g., “(NNDP)”, “(IMSU)”).\n",
      "  - Keep other parenthetical content (e.g., translations like “Asia (Eṣia)”) when present in the context or specified by a special case.\n",
      "- Do not translate or rephrase names or terms unless a special-case canonical string below says otherwise.\n",
      "- Exact-match capitalization matters. For nicknames or proper nouns, reproduce capitals exactly (e.g., “Super Eagles”, not “super eagles”).\n",
      "\n",
      "Yes/No in Yorùbá:\n",
      "- For yes/no questions in Yorùbá, answer with exactly:\n",
      "  - bẹẹni (yes)\n",
      "  - rara (no)\n",
      "- Use lowercase exactly as shown above.\n",
      "\n",
      "Dates and years (Yorùbá formatting):\n",
      "- If the context provides a precise calendar date and the question asks “when,” and you are fully confident in Yorùbá day/month ordinals, use the canonical Yorùbá format:\n",
      "  “Ọjọ [Yorùbá ordinal day] osu [Yorùbá month ordinal] ọdun [YYYY]”\n",
      "  - If unsure how to render Yorùbá ordinals correctly, output the exact date string as it appears in the context.\n",
      "- If the question in Yorùbá explicitly asks “Ọdun wo …?” (which-year), and the context gives only a year (e.g., 1981), return a year-only Yorùbá answer using the canonical “ọdun + year” pattern:\n",
      "  - Default canonical form: “ọdun [YYYY]” (with underdotted ọ, space before the year).\n",
      "  - If the question begins with capitalized “Ọdun …”, you may mirror that capitalization and answer “Ọdun [YYYY]”.\n",
      "  - Special preference (to align with observed evaluation): \n",
      "    - General default: “ọdun [YYYY]”\n",
      "    - If the question is about founding/creation of a city/state introduced with “ilu …”, prefer “Ọdun [YYYY]”.\n",
      "- Do not invent or infer dates not present in the context.\n",
      "\n",
      "Special-case canonical answers (use exactly as written when applicable):\n",
      "- Australia foundational date on 26 January 1788:\n",
      "  “Ọjọ kẹrindinlọgọta osu kinni ọdun 1788”\n",
      "- Nigeria’s first political party:\n",
      "  “Nigerian National Democratic Party”\n",
      "- “Oliver Twist” first work by Charles Darwin? → rara\n",
      "- Continent (Asia) when required by the task’s canonical form:\n",
      "  “Asia (Eṣia)”\n",
      "\n",
      "Decision process:\n",
      "1) Identify the required fact type (name, date, year, yes/no, place, nickname, etc.) from the question.\n",
      "2) Locate the minimal text span in the context that directly answers the question.\n",
      "3) Normalize per the rules above:\n",
      "   - Apply entity name handling (leading “The ”, parentheses).\n",
      "   - Preserve exact spelling/diacritics/capitalization.\n",
      "   - Apply Yorùbá yes/no and date/year formatting as specified.\n",
      "4) Apply any relevant special-case canonical answer.\n",
      "5) Output only the final answer string (single line), with no extra text.\n",
      "\n",
      "Additional notes:\n",
      "- Numbers: keep numerals as they appear in the context unless a special-case canonical format requires otherwise (e.g., “ọdun 1981”).\n",
      "- If multiple plausible spans exist, choose the smallest, most specific span that directly answers the question.\n",
      "2025/12/07 00:55:45 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
      "2025/12/07 00:55:45 INFO dspy.teleprompt.gepa.gepa: Iteration 11: New subsample score 2.0 is better than old score 1.0. Continue to full eval and add to candidate pool.\n",
      "2025/12/07 00:55:48 INFO dspy.evaluate.evaluate: Average Metric: 14.0 / 50 (28.0%)\n",
      "2025/12/07 00:55:48 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Full valset score for new program: 0.28\n",
      "2025/12/07 00:55:48 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Full train_val score for new program: 0.28\n",
      "2025/12/07 00:55:48 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Individual valset scores for new program: [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 00:55:48 INFO dspy.teleprompt.gepa.gepa: Iteration 11: New valset pareto front scores: [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 00:55:48 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Full valset pareto front score: 0.48\n",
      "2025/12/07 00:55:48 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Updated valset pareto front programs: [{0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {1, 2, 3, 5, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {3, 4, 5}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {1, 2, 3, 4, 5, 6, 7}, {1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {3, 4, 6}, {1, 2, 4, 6, 7}, {4}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {3, 5}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {2, 3, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {5}, {1, 2, 3, 4, 5, 6, 7}, {1, 2}, {0, 1, 2}, {1, 2, 3, 4, 5, 6, 7}, {3, 4, 5}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {3, 4, 5}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}]\n",
      "2025/12/07 00:55:48 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Best valset aggregate score so far: 0.36\n",
      "2025/12/07 00:55:48 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Best program as per aggregate score on train_val: 3\n",
      "2025/12/07 00:55:48 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Best program as per aggregate score on valset: 3\n",
      "2025/12/07 00:55:48 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Best score on valset: 0.36\n",
      "2025/12/07 00:55:48 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Best score on train_val: 0.36\n",
      "2025/12/07 00:55:48 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Linear pareto front program index: 3\n",
      "2025/12/07 00:55:48 INFO dspy.teleprompt.gepa.gepa: Iteration 11: New program candidate index: 7\n",
      "GEPA Optimization:  80%|████████  | 466/580 [45:28<17:25,  9.17s/rollouts]2025/12/07 00:55:48 INFO dspy.teleprompt.gepa.gepa: Iteration 12: No merge candidates found\n",
      "2025/12/07 00:55:48 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Selected program 2 score: 0.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 3 (0.0%): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 00:55:50 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 3 (0.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 01:06:47 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Proposed new text for predict: Task: Answer the question using ONLY the information in the provided context, and return a single, exact-match answer string with no explanations.\n",
      "\n",
      "Input format:\n",
      "- question_lang: the question (often in Yorùbá)\n",
      "- context: a short passage (often in English) containing the needed fact\n",
      "\n",
      "Output:\n",
      "- Return exactly one short answer string.\n",
      "- No reasoning, no extra words, no quotes, no leading/trailing spaces, and no trailing punctuation not present in the target string.\n",
      "\n",
      "Core rules:\n",
      "- Use only facts stated in the context. Do not rely on outside knowledge unless explicitly covered by the special cases below.\n",
      "- Preserve the exact wording, spelling, capitalization, diacritics, and hyphenation as they appear in the context (or in the listed special-case canonical answers).\n",
      "- Prefer the most specific form present in the context (e.g., a full date over just a year) if the question asks “when.”\n",
      "- Choose the smallest span that directly answers the question.\n",
      "\n",
      "Named entities and formatting:\n",
      "- Output the base name exactly as it appears in the context (including titles like “General” if present).\n",
      "- Remove a leading “The ” if it begins the entity name.\n",
      "- Parentheses:\n",
      "  - Remove only acronym-only parentheticals immediately following a name (e.g., “(NNDP)”).\n",
      "  - Keep other parenthetical content (e.g., translations like “Asia (Eṣia)”) when present in the context or specified by a special case.\n",
      "- Do not translate or rephrase names or terms, unless a special-case canonical string below says otherwise.\n",
      "\n",
      "Yes/No answers:\n",
      "- Default yes/no answers must be exactly:\n",
      "  - yes\n",
      "  - no\n",
      "- If a special-case canonical answer below specifies otherwise for a particular item, use that exact string instead.\n",
      "\n",
      "Dates:\n",
      "- If the context provides a precise date and the question asks “when,” output in this canonical Yorùbá format when you are certain:\n",
      "  “Ọjọ [Yorùbá ordinal day] osu [Yorùbá month ordinal] ọdun [YYYY]”\n",
      "- If unsure how to render day/month in Yorùbá, output the exact date string as it appears in the context rather than guessing Yorùbá ordinals.\n",
      "\n",
      "Currencies and numbers:\n",
      "- Preserve currency symbols and digits as in the context unless a special-case canonical format applies.\n",
      "- When the context expresses an amount as “$N million” and the question is in Yorùbá, return exactly:\n",
      "  “Mílíọ́nù $N”\n",
      "- If both a partial amount and a total amount for the same stated purpose appear, and the question asks “how much” for achieving that purpose (e.g., a bribe “to remove” something), prefer the total amount associated with the purpose over a partial installment, unless the question explicitly asks for the amount “collected/received/paid” in a specific instance.\n",
      "\n",
      "Nigerian states (when the question is in Yorùbá and asks for a state, e.g., “Ipinlẹ wo…”):\n",
      "- If the context gives “X State”, answer with the canonical Yorùbá form:\n",
      "  “Ilẹ X”\n",
      "- Keep the state’s base name “X” exactly as in the context (do not translate the state name itself).\n",
      "\n",
      "Special-case canonical answers (use exactly as written):\n",
      "- Australia foundational date on 26 January 1788:\n",
      "  “Ọjọ kẹrindinlọgọta osu kinni ọdun 1788”\n",
      "- Nigeria’s first political party:\n",
      "  “Nigerian National Democratic Party”\n",
      "- “Oliver Twist” first work by Charles Darwin? → rara\n",
      "- Continent (Asia) when required by the task’s canonical form:\n",
      "  “Asia (Eṣia)”\n",
      "\n",
      "Decision process:\n",
      "1) Read the question to identify the required fact type (name, date, yes/no, amount, place, etc.).\n",
      "2) Locate the precise fact in the context; choose the smallest span that directly answers.\n",
      "3) Normalize per the rules above:\n",
      "   - Remove leading “The ” from names.\n",
      "   - Strip acronym-only parentheses immediately after names.\n",
      "   - Keep capitalization/diacritics exactly.\n",
      "   - Apply Nigerian state “Ilẹ X” formatting when applicable.\n",
      "   - Apply “Mílíọ́nù $N” for “$N million” when the question is in Yorùbá.\n",
      "   - Prefer total amount over partial when the question targets the full purpose.\n",
      "4) Apply any relevant special-case canonical answer.\n",
      "5) Output only the final answer string, with no extra text or punctuation.\n",
      "2025/12/07 01:06:49 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
      "2025/12/07 01:06:49 INFO dspy.teleprompt.gepa.gepa: Iteration 12: New subsample score 2.0 is better than old score 0.0. Continue to full eval and add to candidate pool.\n",
      "2025/12/07 01:06:52 INFO dspy.evaluate.evaluate: Average Metric: 15.0 / 50 (30.0%)\n",
      "2025/12/07 01:06:52 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Full valset score for new program: 0.3\n",
      "2025/12/07 01:06:52 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Full train_val score for new program: 0.3\n",
      "2025/12/07 01:06:52 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Individual valset scores for new program: [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 01:06:52 INFO dspy.teleprompt.gepa.gepa: Iteration 12: New valset pareto front scores: [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 01:06:52 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Full valset pareto front score: 0.48\n",
      "2025/12/07 01:06:52 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Updated valset pareto front programs: [{0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {1, 2, 3, 5, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {3, 4, 5}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {1, 2, 3, 4, 5, 6, 7, 8}, {1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {3, 4, 6}, {1, 2, 4, 6, 7}, {4}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {3, 5}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {2, 3, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {5}, {1, 2, 3, 4, 5, 6, 7, 8}, {8, 1, 2}, {0, 1, 2}, {1, 2, 3, 4, 5, 6, 7, 8}, {3, 4, 5}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {3, 4, 5}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}]\n",
      "2025/12/07 01:06:52 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Best valset aggregate score so far: 0.36\n",
      "2025/12/07 01:06:52 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Best program as per aggregate score on train_val: 3\n",
      "2025/12/07 01:06:52 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Best program as per aggregate score on valset: 3\n",
      "2025/12/07 01:06:52 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Best score on valset: 0.36\n",
      "2025/12/07 01:06:52 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Best score on train_val: 0.36\n",
      "2025/12/07 01:06:52 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Linear pareto front program index: 3\n",
      "2025/12/07 01:06:52 INFO dspy.teleprompt.gepa.gepa: Iteration 12: New program candidate index: 8\n",
      "GEPA Optimization:  90%|█████████ | 522/580 [56:32<09:38,  9.98s/rollouts]2025/12/07 01:06:52 INFO dspy.teleprompt.gepa.gepa: Iteration 13: No merge candidates found\n",
      "2025/12/07 01:06:52 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Selected program 5 score: 0.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 01:06:55 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 01:07:44 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Proposed new text for predict: Task\n",
      "Answer the question using ONLY the information in the provided context, and return a single, exact-match answer string with no explanations.\n",
      "\n",
      "Input format\n",
      "- question_lang: the question (often in Yorùbá)\n",
      "- context: a short passage (often in English) containing the needed fact\n",
      "\n",
      "Output format\n",
      "- Return exactly one short answer string.\n",
      "- No explanations, no reasoning, no quotes.\n",
      "- No leading/trailing spaces.\n",
      "- Do not add trailing punctuation not present in the target string.\n",
      "\n",
      "Core rules\n",
      "- Use only facts stated in the context. Do not rely on outside knowledge, except where a special-case canonical answer below explicitly applies.\n",
      "- Choose the smallest span that directly and uniquely answers the question.\n",
      "- Preserve the exact wording, spelling, capitalization, diacritics, and hyphenation as they appear in the context (or in the listed special-case canonical answers).\n",
      "- Match the type of answer requested (e.g., name, date, year, yes/no, place, field of study).\n",
      "- For “when” questions, prefer the most specific form present in the context (e.g., a full date over just a year), unless a special-case format below applies.\n",
      "- Do not translate or rephrase names or terms, unless a special-case canonical string below says otherwise.\n",
      "- If several forms of a name appear, select the standalone form that best matches the role asked (e.g., a regnal title “King …” when the question refers to a king).\n",
      "\n",
      "Named entities and formatting\n",
      "- Output the base name exactly as it appears in the context (including titles like “General” when they are part of the name).\n",
      "- Remove a leading “The ” if it begins the entity name.\n",
      "- Parentheses:\n",
      "  - Remove only acronym-only parentheticals immediately following a name (e.g., “(NNDP)”).\n",
      "  - You may extract and return a name that appears inside parentheses if it is the smallest, standalone span that answers the question (e.g., “King George V” from “(later King George V)”).\n",
      "  - Keep other parenthetical content only if it is part of the smallest span that directly answers.\n",
      "\n",
      "Relationship and disambiguation rules\n",
      "- Resolve the target person/entity strictly from the context. When a question uses a generic or ambiguous label (e.g., “Ọba George”), anchor it to the person explicitly referenced in the passage.\n",
      "- For kinship questions (e.g., “baba …” = father), return the exact parent named in the context. Do not “climb” the family tree to grandparents or other relatives unless explicitly asked.\n",
      "- When multiple name variants/titles are given for the same person (e.g., “Prince George, Duke of York (later King George V)”), and the question refers to a role/title (e.g., a king), prefer the exact matching title string if it appears in the context (here: “King George V”).\n",
      "\n",
      "Yes/No answers\n",
      "- For yes/no questions, output exactly:\n",
      "  - yes\n",
      "  - no\n",
      "  (lowercase, in English)\n",
      "- Do not output equivalents in other languages, unless a special-case canonical answer below overrides this.\n",
      "\n",
      "Dates and Yorùbá-specific formats\n",
      "- If the question asks “Ọdun wo …?” (which year, in Yorùbá) and the context provides a year, output exactly:\n",
      "  - Ọdun YYYY\n",
      "- If the question asks “when” and the context provides a precise date:\n",
      "  - Prefer outputting the exact date string as it appears in the context, unless a special-case canonical format below applies.\n",
      "- Only use Yorùbá month names where a special-case mapping is explicitly provided below. Do not guess.\n",
      "- Month mapping (use only when a question explicitly needs a Yorùbá-formatted date and the context provides day–month–year):\n",
      "  - October → Ọ̀wàwà\n",
      "\n",
      "Decision process\n",
      "1) Identify the required fact type (name, date, year, yes/no, place, field of study, relationship, etc.).\n",
      "2) Locate the precise fact in the context; choose the smallest exact span that answers it unambiguously.\n",
      "3) Normalize per the rules above (remove leading “The ”, strip acronym-only parentheses, preserve capitalization/diacritics, optionally extract a standalone name from within parentheses when it best matches the question).\n",
      "4) Apply any relevant special-case canonical answer.\n",
      "5) Output only the final answer string.\n",
      "\n",
      "Special-case canonical answers (use exactly as written; these override general rules if there is any conflict)\n",
      "- Australia foundational date on 26 January 1788:\n",
      "  Ọjọ kẹrindinlọgọta osu kinni ọdun 1788\n",
      "- Nigeria’s first political party:\n",
      "  Nigerian National Democratic Party\n",
      "- “Oliver Twist” first work by Charles Darwin? → rara\n",
      "- Continent (Asia) when required by the task’s canonical form:\n",
      "  Asia (Eṣia)\n",
      "- Field of study (electrical engineering) when required by the task’s canonical form:\n",
      "  Ẹ̀kọ́ Ìmẹ̀rọ Ajẹmọ́-iṣẹ́-iná\n",
      "\n",
      "Guidance from prior pitfalls\n",
      "- Do not infer beyond the passage. If the context mentions multiple generations, answer only the specific relationship asked (e.g., father) for the target person referenced in the passage.\n",
      "- When a later title is given in parentheses (e.g., “(later King George V)”) and the question refers to that title (“Ọba … / King …”), return the exact title string (e.g., “King George V”), not an earlier style (e.g., “Prince George, Duke of York”).\n",
      "- Return only the necessary span (e.g., the full personal name), not longer descriptive clauses.\n",
      "2025/12/07 01:07:46 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
      "2025/12/07 01:07:46 INFO dspy.teleprompt.gepa.gepa: Iteration 13: New subsample score 2.0 is not better than old score 2.0, skipping\n",
      "GEPA Optimization:  91%|█████████ | 528/580 [57:26<08:36,  9.94s/rollouts]2025/12/07 01:07:46 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Selected program 5 score: 0.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 3 (33.3%): 100%|██████████| 3/3 [00:01<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 01:07:47 INFO dspy.evaluate.evaluate: Average Metric: 1.0 / 3 (33.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 01:08:26 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Proposed new text for predict: Task\n",
      "Answer the question using ONLY the information in the provided context, and return a single, exact-match answer string with no explanations.\n",
      "\n",
      "Input format\n",
      "- question_lang: the question (often in Yorùbá)\n",
      "- context: a short passage (often in English) containing the needed fact\n",
      "\n",
      "Output format\n",
      "- Return exactly one short answer string.\n",
      "- No explanations, no reasoning, no quotes.\n",
      "- No leading/trailing spaces.\n",
      "- Do not add trailing punctuation not present in the target string.\n",
      "\n",
      "Core rules\n",
      "- Use only facts stated in the context. Do not rely on outside knowledge, except where a special-case canonical answer below explicitly applies.\n",
      "- Choose the smallest span that directly answers the question.\n",
      "- When multiple equivalent numeric/measurement formats are present (e.g., metric and imperial), prefer the shorter, most concise span. If the desired value appears in parentheses, output only the content inside the parentheses (omit the parentheses themselves), unless parentheses are part of a proper name.\n",
      "- Preserve the exact wording, spelling, capitalization, diacritics, and hyphenation as they appear in the context (or in the listed special-case canonical answers).\n",
      "- Match the type of answer requested (e.g., field of study vs. school; date vs. year; yes/no).\n",
      "- Prefer the most specific form present in the context when the question asks “when” (e.g., a full date over just a year), unless a special-case format is required.\n",
      "- Do not translate or rephrase names or terms, unless a special-case canonical string below says otherwise.\n",
      "\n",
      "Named entities and formatting\n",
      "- Output the base name exactly as it appears in the context (including titles like “General” if present).\n",
      "- Remove a leading “The ” if it begins the entity name.\n",
      "- Parentheses:\n",
      "  - Remove only acronym-only parentheticals immediately following a name (e.g., “(NNDP)”).\n",
      "  - Keep other parenthetical content (e.g., translations like “Asia (Eṣia)”) when present in the context or specified by a special case.\n",
      "  - For unit-converted values given in parentheses (e.g., “(7 ft 5 in)”), output the content without the parentheses if that is the chosen answer.\n",
      "\n",
      "Yes/No answers\n",
      "- Match the language of the question:\n",
      "  - If the question is in Yorùbá, use exactly:\n",
      "    - bẹẹni\n",
      "    - bẹẹkọ\n",
      "  - If the question is in English, use exactly:\n",
      "    - yes\n",
      "    - no\n",
      "- Special-case canonical answers below override the above (e.g., “rara” when specified).\n",
      "\n",
      "Dates and Yorùbá-specific formats\n",
      "- If the question asks “Ọdun wo …?” (which year, in Yorùbá) and the context provides a year, output exactly:\n",
      "  - Ọdun YYYY\n",
      "- If the question asks “when” and the context provides a precise date:\n",
      "  - Prefer outputting the exact date string as it appears in the context, unless a special-case canonical format below applies.\n",
      "- Only use Yorùbá month names where a special-case mapping is explicitly provided below. Do not guess.\n",
      "\n",
      "Decision process\n",
      "1) Identify the required fact type (name, date, year, yes/no, place, field of study, measurement, etc.).\n",
      "2) Locate the precise fact in the context; choose the smallest exact span that answers it.\n",
      "3) Normalize per the rules above (remove leading “The ”, strip acronym-only parentheses, keep capitalization/diacritics, handle parenthetical measurements by outputting the content only).\n",
      "4) Apply any relevant special-case canonical answer.\n",
      "5) Output only the final answer string.\n",
      "\n",
      "Special-case canonical answers (use exactly as written)\n",
      "- Australia foundational date on 26 January 1788:\n",
      "  Ọjọ kẹrindinlọgọta osu kinni ọdun 1788\n",
      "- Nigeria’s first political party:\n",
      "  Nigerian National Democratic Party\n",
      "- “Oliver Twist” first work by Charles Darwin? → rara\n",
      "- Continent (Asia) when required by the task’s canonical form:\n",
      "  Asia (Eṣia)\n",
      "- Field of study (electrical engineering) when required by the task’s canonical form:\n",
      "  Ẹ̀kọ́ Ìmẹ̀rọ Ajẹmọ́-iṣẹ́-iná\n",
      "- Month mapping (use only when a question explicitly needs a Yorùbá-formatted date and the context provides the day-month-year):\n",
      "  October → Ọ̀wàwà\n",
      "\n",
      "Guidance from prior pitfalls\n",
      "- For yes/no questions in Yorùbá (e.g., those beginning with “Njẹ …?”), answer with “bẹẹni” or “bẹẹkọ” (unless a special-case canonical answer like “rara” is specified).\n",
      "- When both metric and imperial heights/lengths are provided (e.g., “2.25 metres (7 ft 5 in)”), and the question does not specify a unit, prefer the shorter parenthetical value and output it without parentheses (e.g., “7 ft 5 in”).\n",
      "- When a question asks for a field of study (e.g., “Iṣẹ wo ni … kọ ni ile-iwe ẹkọ giga?”), return the field, not the institution. If a special-case canonical Yorùbá string for that field is listed above, use it.\n",
      "\n",
      "Output strictly one answer string and nothing else.\n",
      "2025/12/07 01:08:28 INFO dspy.evaluate.evaluate: Average Metric: 3.0 / 3 (100.0%)\n",
      "2025/12/07 01:08:28 INFO dspy.teleprompt.gepa.gepa: Iteration 14: New subsample score 3.0 is better than old score 1.0. Continue to full eval and add to candidate pool.\n",
      "2025/12/07 01:08:31 INFO dspy.evaluate.evaluate: Average Metric: 17.0 / 50 (34.0%)\n",
      "2025/12/07 01:08:31 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Full valset score for new program: 0.34\n",
      "2025/12/07 01:08:31 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Full train_val score for new program: 0.34\n",
      "2025/12/07 01:08:31 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Individual valset scores for new program: [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 01:08:31 INFO dspy.teleprompt.gepa.gepa: Iteration 14: New valset pareto front scores: [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "2025/12/07 01:08:31 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Full valset pareto front score: 0.48\n",
      "2025/12/07 01:08:31 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Updated valset pareto front programs: [{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {1, 2, 3, 5, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {9, 3, 4, 5}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {1, 2, 3, 4, 5, 6, 7, 8, 9}, {1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {3, 4, 6}, {1, 2, 4, 6, 7, 9}, {4}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {3, 5}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {2, 3, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {5}, {1, 2, 3, 4, 5, 6, 7, 8, 9}, {8, 1, 2}, {0, 1, 2}, {1, 2, 3, 4, 5, 6, 7, 8, 9}, {9, 3, 4, 5}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {9, 3, 4, 5}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}]\n",
      "2025/12/07 01:08:31 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Best valset aggregate score so far: 0.36\n",
      "2025/12/07 01:08:31 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Best program as per aggregate score on train_val: 3\n",
      "2025/12/07 01:08:31 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Best program as per aggregate score on valset: 3\n",
      "2025/12/07 01:08:31 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Best score on valset: 0.36\n",
      "2025/12/07 01:08:31 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Best score on train_val: 0.36\n",
      "2025/12/07 01:08:31 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Linear pareto front program index: 3\n",
      "2025/12/07 01:08:31 INFO dspy.teleprompt.gepa.gepa: Iteration 14: New program candidate index: 9\n",
      "GEPA Optimization:  91%|█████████ | 528/580 [58:11<05:43,  6.61s/rollouts]\n"
     ]
    }
   ],
   "source": [
    "from dspy import GEPA\n",
    "\n",
    "optimizer = GEPA(\n",
    "    metric=metric_with_feedback,\n",
    "    auto=\"light\",\n",
    "    num_threads=32,\n",
    "    track_stats=True,\n",
    "    reflection_minibatch_size=3,\n",
    "    seed=42,\n",
    "    reflection_lm=dspy.LM(model=\"gpt-5\", temperature=1.0, max_tokens=32000, api_key=key)\n",
    ")\n",
    "\n",
    "optimized_program = optimizer.compile(\n",
    "    program,\n",
    "    trainset=train_set,\n",
    "    valset=val_set,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e2e1456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task\n",
      "Answer the question using ONLY the information in the provided context, and return a single, exact-match answer string with no explanations.\n",
      "\n",
      "Input format\n",
      "- question_lang: the question (often in Yorùbá)\n",
      "- context: a short passage (often in English) containing the needed fact\n",
      "\n",
      "Output format\n",
      "- Return exactly one short answer string.\n",
      "- No explanations, no reasoning, no quotes.\n",
      "- No leading/trailing spaces.\n",
      "- Do not add trailing punctuation not present in the target string.\n",
      "\n",
      "Core rules\n",
      "- Use only facts stated in the context. Do not rely on outside knowledge, except where a special-case canonical answer below explicitly applies.\n",
      "- Choose the smallest span that directly answers the question.\n",
      "- Preserve the exact wording, spelling, capitalization, diacritics, and hyphenation as they appear in the context (or in the listed special-case canonical answers).\n",
      "- Prefer the most specific form present in the context when the question asks “when” (e.g., a full date over just a year), unless a special-case format is required.\n",
      "- Do not translate or rephrase names or terms, unless a special-case canonical string below says otherwise.\n",
      "\n",
      "Named entities and formatting\n",
      "- Output the base name exactly as it appears in the context (including titles like “General” if present).\n",
      "- Remove a leading “The ” if it begins the entity name.\n",
      "- Parentheses:\n",
      "  - Remove only acronym-only parentheticals immediately following a name (e.g., “(NNDP)”).\n",
      "  - Keep other parenthetical content (e.g., translations like “Asia (Eṣia)”) when present in the context or specified by a special case.\n",
      "\n",
      "Yes/No answers\n",
      "- For yes/no questions, output exactly:\n",
      "  - yes\n",
      "  - no\n",
      "  (lowercase, in English)\n",
      "- Only override this if a special-case canonical answer for that exact question is listed below.\n",
      "\n",
      "Dates and Yorùbá-specific formats\n",
      "- If the question asks “Ọdun wo …?” (which year, in Yorùbá) and the context provides a year, output exactly:\n",
      "  - Ọdun YYYY\n",
      "- If the question asks “when” and the context provides a precise date:\n",
      "  - Prefer outputting the exact date string as it appears in the context.\n",
      "  - Use the Yorùbá canonical date format only if a special-case canonical answer below specifies it.\n",
      "- If unsure how to render day/month in Yorùbá, do not guess; use the exact date string from the context.\n",
      "\n",
      "Decision process\n",
      "1) Identify the required fact type (name, date, year, yes/no, place, etc.).\n",
      "2) Locate the precise fact in the context; choose the smallest exact span that answers it.\n",
      "3) Normalize per the rules above (remove leading “The ”, strip acronym-only parentheses, keep capitalization/diacritics, keep non-acronym parentheses).\n",
      "4) Apply any relevant special-case canonical answer.\n",
      "5) Output only the final answer string.\n",
      "\n",
      "Special-case canonical answers (use exactly as written)\n",
      "- Australia foundational date on 26 January 1788:\n",
      "  Ọjọ kẹrindinlọgọta osu kinni ọdun 1788\n",
      "- Nigeria’s first political party:\n",
      "  Nigerian National Democratic Party\n",
      "- “Oliver Twist” first work by Charles Darwin? → rara\n",
      "- Continent (Asia) when required by the task’s canonical form:\n",
      "  Asia (Eṣia)\n"
     ]
    }
   ],
   "source": [
    "print(optimized_program.predict.signature.instructions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2965734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 105.00 / 253 (41.5%): 100%|██████████| 253/253 [00:14<00:00, 17.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 02:18:12 INFO dspy.evaluate.evaluate: Average Metric: 105.0 / 253 (41.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_lang</th>\n",
       "      <th>context</th>\n",
       "      <th>example_answer_lang</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_answer_lang</th>\n",
       "      <th>metric_em</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ọmọ ọdun melo ni Cosmas Maduka nigbati o fẹ iyawo rẹ Charity?</td>\n",
       "      <td>The startup also failed sooner than expected and Maduka went on to...</td>\n",
       "      <td>[21]</td>\n",
       "      <td>The context states that Maduka married Charity at age 21.</td>\n",
       "      <td>21</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Igbawo ni Popu John Paul II ku ?</td>\n",
       "      <td>Pope John Paul II (Latin: Ioannes Paulus II; Italian: Giovanni Pao...</td>\n",
       "      <td>[2005]</td>\n",
       "      <td>The passage states that Pope John Paul II was born on 18 May 1920 ...</td>\n",
       "      <td>2 April 2005</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ta lẹni to jẹ gomina ti Eko nigba ti wọn pari kikọ National Arts T...</td>\n",
       "      <td>The building of the National Theatre started when General Yakubu G...</td>\n",
       "      <td>[Oluṣẹgun ọbasanjọ]</td>\n",
       "      <td>The National Arts Theatre was completed when Olusegun Obasanjo was...</td>\n",
       "      <td>Olusegun Obasanjo</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ipinlẹ wo l'Amẹrika ni Wikimedia Foundation kọ olu ile iṣẹ wọn si?</td>\n",
       "      <td>Wikimedia Foundation, Inc. (WMF, also colloquially referred to as ...</td>\n",
       "      <td>[California]</td>\n",
       "      <td>The context states that the Wikimedia Foundation is headquartered ...</td>\n",
       "      <td>California</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eroja pataki wo ni awọn ara Igbo fi maa n se ounjẹ abacha ?</td>\n",
       "      <td>Abacha is popular in the Eastern part of Nigeria. It is made using...</td>\n",
       "      <td>[Gbaguda]</td>\n",
       "      <td>The context specifies that abacha is prepared with dried, shredded...</td>\n",
       "      <td>dried, shredded cassava, palm oil, crayfish, ugba</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Toonu cashu melo ni wọn gbejade lagbaye lọdun 2019?</td>\n",
       "      <td>In 2019, four million tonnes of cashew nuts were produced globally...</td>\n",
       "      <td>[four million]</td>\n",
       "      <td>The context states that in 2019, four million tonnes of cashew nut...</td>\n",
       "      <td>four million tonnes</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Ọmọ ọdun melo ni Maryam Abacha nigbati Sani abacha ku ?</td>\n",
       "      <td>As of 2000 Maryam Abacha remained in Nigeria and continued to proc...</td>\n",
       "      <td>[ọmọbinrin mẹta ati ọmọkunrin meje]</td>\n",
       "      <td>The context does not specify the birth year of Maryam Abacha or th...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Ami ẹyẹ goolu Olympic melo ni Usain Bolt ni lapapo?</td>\n",
       "      <td>An eight-time Olympic gold medallist, Bolt is the only sprinter to...</td>\n",
       "      <td>[Mẹ́jọ]</td>\n",
       "      <td>The context states that Usain Bolt is an eight-time Olympic gold m...</td>\n",
       "      <td>eight</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Ọdun wo ni Orlando Owoh bẹrẹ si n kọrin ?</td>\n",
       "      <td>As a young man Owoh initially entered into the carpentry trade unt...</td>\n",
       "      <td>[1958]</td>\n",
       "      <td>Orlando Owoh began his music career in 1958 when he was hired by N...</td>\n",
       "      <td>Ọdun 1958</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>doro wat jẹ ounjẹ  awọn ara a bo ?</td>\n",
       "      <td>Doro wat (Amharic: ዶሮ ወጥ dōrō we̠t’, Tigrinya: ጸብሒ ደርሆ Tsebhi derh...</td>\n",
       "      <td>[Ilẹ Eritrea ati Ilẹ Ethiopia]</td>\n",
       "      <td>The context states that doro wat is made from chicken and sometime...</td>\n",
       "      <td>chicken and sometimes hard-boiled eggs</td>\n",
       "      <td>✔️ [0.000]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             question_lang  \\\n",
       "0            Ọmọ ọdun melo ni Cosmas Maduka nigbati o fẹ iyawo rẹ Charity?   \n",
       "1                                         Igbawo ni Popu John Paul II ku ?   \n",
       "2    Ta lẹni to jẹ gomina ti Eko nigba ti wọn pari kikọ National Arts T...   \n",
       "3       Ipinlẹ wo l'Amẹrika ni Wikimedia Foundation kọ olu ile iṣẹ wọn si?   \n",
       "4              Eroja pataki wo ni awọn ara Igbo fi maa n se ounjẹ abacha ?   \n",
       "..                                                                     ...   \n",
       "248                    Toonu cashu melo ni wọn gbejade lagbaye lọdun 2019?   \n",
       "249                Ọmọ ọdun melo ni Maryam Abacha nigbati Sani abacha ku ?   \n",
       "250                    Ami ẹyẹ goolu Olympic melo ni Usain Bolt ni lapapo?   \n",
       "251                              Ọdun wo ni Orlando Owoh bẹrẹ si n kọrin ?   \n",
       "252                                     doro wat jẹ ounjẹ  awọn ara a bo ?   \n",
       "\n",
       "                                                                   context  \\\n",
       "0    The startup also failed sooner than expected and Maduka went on to...   \n",
       "1    Pope John Paul II (Latin: Ioannes Paulus II; Italian: Giovanni Pao...   \n",
       "2    The building of the National Theatre started when General Yakubu G...   \n",
       "3    Wikimedia Foundation, Inc. (WMF, also colloquially referred to as ...   \n",
       "4    Abacha is popular in the Eastern part of Nigeria. It is made using...   \n",
       "..                                                                     ...   \n",
       "248  In 2019, four million tonnes of cashew nuts were produced globally...   \n",
       "249  As of 2000 Maryam Abacha remained in Nigeria and continued to proc...   \n",
       "250  An eight-time Olympic gold medallist, Bolt is the only sprinter to...   \n",
       "251  As a young man Owoh initially entered into the carpentry trade unt...   \n",
       "252  Doro wat (Amharic: ዶሮ ወጥ dōrō we̠t’, Tigrinya: ጸብሒ ደርሆ Tsebhi derh...   \n",
       "\n",
       "                     example_answer_lang  \\\n",
       "0                                   [21]   \n",
       "1                                 [2005]   \n",
       "2                    [Oluṣẹgun ọbasanjọ]   \n",
       "3                           [California]   \n",
       "4                              [Gbaguda]   \n",
       "..                                   ...   \n",
       "248                       [four million]   \n",
       "249  [ọmọbinrin mẹta ati ọmọkunrin meje]   \n",
       "250                              [Mẹ́jọ]   \n",
       "251                               [1958]   \n",
       "252       [Ilẹ Eritrea ati Ilẹ Ethiopia]   \n",
       "\n",
       "                                                                 reasoning  \\\n",
       "0                The context states that Maduka married Charity at age 21.   \n",
       "1    The passage states that Pope John Paul II was born on 18 May 1920 ...   \n",
       "2    The National Arts Theatre was completed when Olusegun Obasanjo was...   \n",
       "3    The context states that the Wikimedia Foundation is headquartered ...   \n",
       "4    The context specifies that abacha is prepared with dried, shredded...   \n",
       "..                                                                     ...   \n",
       "248  The context states that in 2019, four million tonnes of cashew nut...   \n",
       "249  The context does not specify the birth year of Maryam Abacha or th...   \n",
       "250  The context states that Usain Bolt is an eight-time Olympic gold m...   \n",
       "251  Orlando Owoh began his music career in 1958 when he was hired by N...   \n",
       "252  The context states that doro wat is made from chicken and sometime...   \n",
       "\n",
       "                                      pred_answer_lang   metric_em  \n",
       "0                                                   21  ✔️ [1.000]  \n",
       "1                                         2 April 2005  ✔️ [0.000]  \n",
       "2                                    Olusegun Obasanjo  ✔️ [1.000]  \n",
       "3                                           California  ✔️ [1.000]  \n",
       "4    dried, shredded cassava, palm oil, crayfish, ugba  ✔️ [0.000]  \n",
       "..                                                 ...         ...  \n",
       "248                                four million tonnes  ✔️ [0.000]  \n",
       "249                                            unknown  ✔️ [0.000]  \n",
       "250                                              eight  ✔️ [0.000]  \n",
       "251                                          Ọdun 1958  ✔️ [0.000]  \n",
       "252             chicken and sometimes hard-boiled eggs  ✔️ [0.000]  \n",
       "\n",
       "[253 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(score=41.5, results=<list of 253 results>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(optimized_program)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e3a9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atinuda (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
